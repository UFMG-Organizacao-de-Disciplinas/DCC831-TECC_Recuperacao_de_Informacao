# Resumo P2

## Aulas

| Aula | Slide                     | Data       | PDF              | MD             | Resumo              | Tópico                                                                |
| ---- | :------------------------ | ---------- | ---------------- | -------------- | ------------------- | --------------------------------------------------------------------- |
| 14   | 14-quality-models         | 07/05/2025 | [pdf_14][pdf_14] | [md_14][md_14] | [res_14][res_md_14] | Quality Models                                                        |
| 15   | 15-feedback-models        | 12/05/2025 | [pdf_15][pdf_15] | [md_15][md_15] |                     | Feedback Models                                                       |
| 16   | 16-diversification-models | 14/05/2025 | [pdf_16][pdf_16] | [md_16][md_16] |                     | Diversification Models                                                |
| 17   | 17-ltr-fundamentals       | 19/05/2025 | [pdf_17][pdf_17] | [md_17][md_17] |                     | Learning to Rank: Fundamentals                                        |
| 18   | 18-ltr-pointwise          | 21/05/2025 | [pdf_18][pdf_18] | [md_18][md_18] |                     | Learning to Rank: Algorithms; Learning to Rank: Pointwise             |
| 18   | 19-ltr-pairwise-listwise  | 21/05/2025 | [pdf_19][pdf_19] | [md_19][md_19] |                     | Learning to Rank: Algorithms; Learning to Rank: Pairwise and Listwise |
| 19   | 20-neural-reranking       | 26/05/2025 | [pdf_20][pdf_20] | [md_20][md_20] |                     | Neural Models: Reranking                                              |
| 20   | 21-neural-retrieval       | 28/05/2025 | [pdf_21][pdf_21] | [md_21][md_21] |                     | Neural Models: Retrieval                                              |
|      | 22-neural-generation      |            | [pdf_22][pdf_22] | [md_22][md_22] |                     | Generative Information Retrieval                                      |
| 21   | 23-online-evaluation      | 02/06/2025 | [pdf_23][pdf_23] | [md_23][md_23] |                     | Online Evaluation                                                     |
| 22   | 24-oltr                   | 04/06/2025 | [pdf_24][pdf_24] | [md_24][md_24] |                     | Online Learning to Rank                                               |

<!-- Resumos -->

[res_md_14]: Slides/14-quality-models-resumo.md

<!-- Classnotes -->

[md_14]: Slides/14-quality-models.md
[md_15]: Slides/15-feedback-models.md
[md_16]: Slides/16-diversification-models.md
[md_17]: Slides/17-ltr-fundamentals.md
[md_18]: Slides/18-ltr-pointwise.md
[md_19]: Slides/19-ltr-pairwise-listwise.md
[md_20]: Slides/20-neural-reranking.md
[md_21]: Slides/21-neural-retrieval.md
[md_22]: Slides/22-neural-generation.md
[md_23]: Slides/23-online-evaluation.md
[md_24]: Slides/24-oltr.md

<!-- PDFs -->

[pdf_14]: Slides/14-quality-models.pdf
[pdf_15]: Slides/15-feedback-models.pdf
[pdf_16]: Slides/16-diversification-models.pdf
[pdf_17]: Slides/17-ltr-fundamentals.pdf
[pdf_18]: Slides/18-ltr-pointwise.pdf
[pdf_19]: Slides/19-ltr-pairwise-listwise.pdf
[pdf_20]: Slides/20-neural-reranking.pdf
[pdf_21]: Slides/21-neural-retrieval.pdf
[pdf_22]: Slides/22-neural-generation.pdf
[pdf_23]: Slides/23-online-evaluation.pdf
[pdf_24]: Slides/24-oltr.pdf

## Conteúdos

### 14 - Quality Models

### 15 - Feedback Models

- Analisar a relevância de um documento baseado na relevância dos documentos anteriores.
- Rocchio: se afasta do centroide dos não relevantes e se aproxima do centroide dos relevantes.

### 16 - Diversification Models

- **Probability Ranking Principle (PRP):** conceito onde a ordenação de itens de informação por probabilidade decrescente de relevância resulta em eficácia ótima de recuperação.
  - **Assumptions:**
    - **A1:** A probabilidade de relevância é estimada com certeza, sem medida de risco.
      - **Problemas:**
        - **Ambiguity:** Ambiguidade na representação das informações e necessidades.
        - **Underspecification:** múltiplos aspectos podem ser relevantes para uma consulta.
          - Toda query sofre disso
    - **A2:** A probabilidade de relevância é estimada independentemente para cada documento.
      - **Problemas:**
        - **Redundancy:** se o primeiro documento já supriu as necessidades do usuário, os demais perdem relevância, mesmo que eles individualmente sejam relevantes.
        - **Diversity:** a diversidade de documentos é importante para cobrir diferentes aspectos da consulta. (resolver a ambiguidade)
        - **Novelty:** talvez um documento mais recente seja mais relevante que outro. O que afeta a redundância.
  - Entende-se então que ambas são falsas. Assim se afastando do conceito de PRP.
- **Greedy Approximation:** iterativamente encontra o próximo documento que melhor cobre os aspectos não cobertos da consulta, considerando a relevância e a diversidade. No geral é eficiente o bastante e com várias funções objetivo na literatura.

---

- Diversification Dimensions
  - **Aspects**
    - **Implicit aspects:** [JV] me parece ser algo específico do documento.
      - **Raw:**
        - **One-hot term vectors:** Indica presença ou ausência de palavras.
        - **Count-based term vectors:** Contagem de termos.
      - **Latent:**
        - **Topic models:** Modelos de tópicos.
        - **Cluster models:** Modelos de agrupamento.
        - **Embeddings:** Representações vetoriais de palavras ou documentos.
    - **Explicit aspects:** [JV] me parece ser algo específico da query.
      - **Fixed aspects:** Categorias de consulta.
      - **Non-fixed aspects:** Sugestões de consulta.
  - **Ranking Strategies**
    - **Novelty:** Cobrir aspectos o mais cedo possível.
    - **Coverage:** Cobrir o máximo de aspectos possível.
    - **Hybrid:** Promover cobertura e novidade.
      - [JV] Segue na ideia do interweaving. É o estado da arte.
    - [JV] Uma abordagem seria perguntar pro usuário qual aspecto ele quer ver, mas isso pode não ser agradável pro usuário.
  - **Maximal Marginal Relevance (MMR)**
    - Fórmula: $f(q, d, D) = \lambda rel(q, d) - (1 - \lambda) \max_{d_j \in D} sim(d, d_j)$
      - Onde:
        - $rel(q, d)$ é a relevância do documento $d$ para a consulta $q$.
        - $sim(d, d_j)$ é a similaridade entre o documento $d$ e outro documento $d_j$ no conjunto $D$. Quanto maior for a similaridade, menor será o score.
        - $\lambda$ é um parâmetro que controla o trade-off entre relevância e novidade.

### 17 - Learning to Rank: Fundamentals

- Modelos de topicalidade
- Modelos de Qualidade
  - Cada um tem benefício em um cenário.
- Combining models: ensembles
- Learning to Rank (LTR)
  - **Features:** Cada modelo representa uma feature
  - **Discriminative:** modelos aprendidos dos dados (machine learning)
    - **Limitações:**
      - Dados limitados
      - Técnicas primitivas
      - Poucas features
    - **Framework:**
      - Dados de treino e validação. Com isso aprende-se o modelo, ele gera um score, e por fim testa se esse score está de acordo com o resultado esperado.
    - **Conceito geral**
      - Aprender função $f: x \to y$ que minimiza a função de perda $\mathcal{L}: f(x) \times y \to R$
      - É parecido com a ideia do Rocchio, porém, aqui o ponto que buscamos nos aproximar é o rótulo certo. Lá,
    - **Aprofundando**
      - **Entrada:** A entrada $x$ é um vetor de features obtida por uma função fictícia $\Phi$ que computa todas as features do vetor de entrada dadas uma query $q$ e um documento $d$.
        - Essas features podem ser dependentes de $d$, de $q$ ou de ambos.
          - $q$: length, type, ...
          - $d$: PageRank, readability, spaminess, ...
          - $(q, d)$: BM25, LM, PL2, ...
      - **Saída:**
        - **Pointwise** (Um documento):
          - um único rótulo $y$, que pode ser binário ($y \in \{0, 1\}$) ou gradado ($y \in \{0, 1, 2, \ldots, k\}$).
          - $x$: documento único; $y$: score ou rótulo
          - Assume que a relevância é independente da query, porém a utilidade de uma feature pode depender da query.
        - **Pairwise** (Pares de documentos):
          - preferência entre dois documentos $d_1$ e $d_2$ para uma consulta $q$
          - $x$: pares de documentos; $y$: ordens parciais entre documentos
          - Não assume independência da query, mas não cobre todas as propriedades do ranking, e o peso do erro varia entre as posições do ranking.
        - **Listwise** (Lista de documentos):
          - ordenação de uma lista de documentos $D$ para uma consulta $q$.
          - $x$: lista de documentos; $y$: ranking completo da lista
          - Define uma loss function referente a toda a lista. O estado da arte é avaliar as metricas de ranking diretamente
      - **Hipótese da função**
        - Linear
        - Árvore
        - Rede neural
        - Como encontrar a melhor? Procure a que tiver a menor perda.
      - **Loss Function:**
        - 0-1
        - valor absoluto
        - quadrático
        - E como encontrar a menor perda?
          - Otimização por coordenada, uma por vez
          - Gradiente descendente, todas ao mesmo tempo
          - Boosting, uma por vez, mas com o erro do modelo anterior

### 18 - Learning to Rank: Algorithms; Learning to Rank: Pointwise

### 19 - Learning to Rank: Algorithms; Learning to Rank: Pairwise and Listwise

### 20 - Neural Models: Reranking

### 21 - Neural Models: Retrieval

### 22 - Generative Information Retrieval

### 23 - Online Evaluation

### 24 - Online Learning to Rank
