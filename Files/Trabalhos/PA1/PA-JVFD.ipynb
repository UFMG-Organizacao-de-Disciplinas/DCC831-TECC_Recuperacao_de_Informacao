{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enunciado do Trabalho\n",
    "\n",
    "Universidade Federal de Minas Gerais\n",
    "\n",
    "Departamento de Ciência da Computação\n",
    "\n",
    "TCC/TSI/TECC: Information Retrieval\n",
    "\n",
    "## Programming Assignment #1 - Web Crawler\n",
    "\n",
    "- **Deadline:** Apr 28th, 2025 23:59 via Moodle\n",
    "\n",
    "### Overview\n",
    "\n",
    "The goal of this assignment is to implement a crawler capable of fetching a mid-sized corpus of webpages in a short time frame while respecting the politeness constraints defined by each crawled website. In addition to the source code of your implementation and the actual crawled documents, your submission must include a characterization of these documents.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "You must use Python 3 for this assignment. Your code must run in a virtual environment **using only the libraries included** in the provided `requirements.txt` file. Execution errors due to missing libraries or incompatible library versions will result in a zero grade. To make sure you have the correct setup, you can test it in one of the [Linux machines provided by the Department of Computer Science $^{1}$][Link_CRC] using the following commands:\n",
    "\n",
    "[Link_CRC]: <https://www.crc.dcc.ufmg.br/doku.php/infraestrutura/laboratorios/linux>\n",
    "\n",
    "```bash\n",
    "$ python3 -m venv pa1\n",
    "$ source pa1/bin/activate\n",
    "$ pip3 install -r /path/to/requirements.txt\n",
    "```\n",
    "\n",
    "\n",
    "### Execution\n",
    "\n",
    "Your implementation should include a `main.py` file, which will be executed in the same virtual environment described above, as follows:\n",
    "\n",
    "```bash\n",
    "$ python3 main.py -s <SEEDS> -n <LIMIT> [-d]\n",
    "```\n",
    "\n",
    "with the following arguments:\n",
    "\n",
    "- **-s \\<SEEDS>:** the path to a file containing a list of seed URLs (one URL per line) for initializing the crawling process.\n",
    "- **-n \\<LIMIT>:** the target number of webpages to be crawled; the crawler should stop its execution once this target is reached.\n",
    "- **-d:** (optional argument) run in debug mode (see below).\n",
    "\n",
    "### Debugging\n",
    "\n",
    "When executed in debugging mode (i.e. when -d is passed as a command-line argument), your implementation must print a record of each crawled webpage to [standard output $^2$][StandardOutput] as it progresses. Such a record must be formatted as a JSON document containing the following fields:\n",
    "\n",
    "[StandardOutput]: <https://en.wikipedia.org/wiki/Standard_streams#Standard_output_(stdout)>\n",
    "\n",
    "- `URL`, containing the page URL;\n",
    "- `Title`, containing the page title;\n",
    "- `Text`, containing the first 20 words from the page visible text;\n",
    "- `Timestamp`, containing the [Unix time $^3$][UnixTime] when the page was crawled.\n",
    "\n",
    "[UnixTime]: <https://en.wikipedia.org/wiki/Unix_time>\n",
    "\n",
    "The following example illustrates the required debugging output format for the first webpage fetched during a crawling execution:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"URL\": \"https://g1.globo.com/\",\n",
    "    \"Title\": \"G1 - O portal de notícias da Globo\",\n",
    "    \"Text\": \"Deseja receber as notícias mais importantes em tempo real? Ative as notificações do G1! Agora não Ativar Gasto familiar Despesa\",\n",
    "    \"Timestamp\": 1649945049\n",
    "}\n",
    "```\n",
    "\n",
    "### Crawling Policies\n",
    "\n",
    "Your implementation must keep a frontier of URLs to be crawled, which must be initialized with the seed URLs provided as input to you with the -s argument. For each URL consumed from the frontier, your implementation must fetch the corresponding webpage, parse it, store the extracted HTML content in the local corpus, and enqueue the extracted outlinks in the frontier to be crawled later. In addition to this standard workflow, **your implementation must abide by the following crawling policies:**\n",
    "\n",
    "1. *Selection Policy:* Starting from the provided seed URLs, your implementation **must only follow discovered links to HTML pages** (i.e. resources with MIME type `text/html`). To improve coverage, you may optionally choose to limit the crawling depth of any given website.\n",
    "2. *Revisitation Policy:* Because this is a one-off crawling exercise, you **must not revisit a previously crawled webpage**. To ensure only new links are crawled, you may choose to normalize URLs and check for duplicates before adding new URLs to the frontier.\n",
    "3. *Parallelization Policy:* To ensure maximum efficiency, you **must parallelize the crawling process across multiple threads**. You may experiment to find an optimal number of threads to maximize your download rate while minimizing the incurred parallelization overhead.\n",
    "4. *Politeness Policy:* To avoid overloading the crawled websites, your implementation [**must abide by the robots exclusion protocol** $^4$][4]. Unless explicitly stated otherwise in a `robots.txt` file, you must obey a delay of at least 100ms between consecutive requests to the same website.\n",
    "5. *Storage Policy:* As the main target for this assignment, your implementation **must crawl and store a total of 100,000 unique webpages**. The raw HTML content of the crawled webpages must be packaged using the [WARC format $^5$][5], with 1,000 webpages stored per WARC file (totalling 100 such files), compressed with gzip to reduce storage costs.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "Before the deadline (Apr 28th, 2025 23:59), you must submit a package file (zip) via Moodle containing the following:\n",
    "\n",
    "1. Source code of your implementation;\n",
    "2. Link to your crawled corpus (stored on Google Drive);\n",
    "3. Documentation file (pdf, max 2 pages).\n",
    "\n",
    "### Grading\n",
    "\n",
    "This assignment is worth a total of 15 points distributed as:\n",
    "\n",
    "- 10 points for your *implementation*, assessed based on the quality of your source code, including its overall organization (modularity, readability, indentation, use of comments) and appropriate use of data structures, as well as on how well it abides by the five aforementioned crawling policies.\n",
    "- 5 points for your *documentation*, assessed based on a [short (pdf) report $^6$][6] describing your implemented data structures and algorithms, their computational complexity, as well as a discussion of their empirical efficiency (e.g. the download rate throughout the crawling execution, the speedup achieved as new threads are added). Your documentation should also include a characterization of your crawled corpus, including (but not limited to) the following statistics: total number of unique domains, size distribution (in terms of number of webpages) per domain, and size distribution (in terms of number of tokens) per webpage.\n",
    "\n",
    "### Teams\n",
    "\n",
    "This assignment must be performed individually. Any sign of plagiarism will be investigated and reported to the appropriate authorities.\n",
    "\n",
    "[4]: <https://en.wikipedia.org/wiki/Robots_exclusion_standard>\n",
    "[5]: <https://en.wikipedia.org/wiki/Web_ARChive>\n",
    "[6]: <https://portalparts.acm.org/hippo/latex_templates/acmart-primary.zip> \"Your documentation should be no longer than 2 pages and use the ACM LATEX template (sample-sigconf.tex)\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do's\n",
    "\n",
    "### Execução\n",
    "\n",
    "- [X] Install `requirements.txt` libraries\n",
    "- Definir os parâmetros de inicialização\n",
    "  - [X] Path to Seeds\n",
    "  - [X] Target Number of Webpages\n",
    "  - [X] Debug Mode\n",
    "\n",
    "### Debugging Prints\n",
    "\n",
    "- [X] URL\n",
    "- [X] Title\n",
    "- [X] Text\n",
    "- [X] Timestamp (Unix time)\n",
    "\n",
    "### Follow Policies\n",
    "\n",
    "- Selection Policy\n",
    "  - [X] only MIME type `text/html`\n",
    "    - CONTENT-TYPE || MIMETYPE\n",
    "  - [ ] Limit crawling depth of any given website (opcional)\n",
    "- Revisitation Policy\n",
    "  - [ ] Normalize URLs before adding to frontier\n",
    "- Parallelization Policy\n",
    "  - [ ] Parallelize the crawling process across multiple threads\n",
    "- Politeness Policy\n",
    "  - [ ] Obey the `robots.txt` file\n",
    "  - [ ] Delay of at least 100ms between consecutive requests to the same website\n",
    "- Storage Policy\n",
    "  - [ ] Store 100,000 unique webpages\n",
    "  - [X] Package using WARC format\n",
    "  - [X] Compress with gzip to reduce storage costs\n",
    "  - [ ] Store at Google Drive\n",
    "\n",
    "### Documentation\n",
    "\n",
    "- 2 pages (pdf)\n",
    "  - [ ] ACM LATEX template (sample-sigconf.tex)\n",
    "    - Data Structures\n",
    "    - Algorithms\n",
    "    - Computational Complexity\n",
    "    - Empirical Efficiency\n",
    "    - Crawled Corpus Characterization\n",
    "      - Total number of unique domains\n",
    "      - Size distribution (in terms of number of webpages) per domain\n",
    "      - Size distribution (in terms of number of tokens) per webpage\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideias:\n",
    "\n",
    "- Explorar urls\n",
    "  - Vasculhar o sitemap\n",
    "  - Árvore de aprendizado descritivo pra armazenar links\n",
    "    - Todas as tarefas computacionalmente intensas devem ser delegadas à threads?\n",
    "    - Armazenar logo quando achar?\n",
    "    - Percorrer a árvore pra poder extrair os dados?\n",
    "    - Percorrer enquanto se preenche?\n",
    "  - Threads\n",
    "    1. Um que fica verificando se novas páginas foram adicionadas aos filhos\n",
    "    2. Em cada filho da raiz\n",
    "\n",
    "- Estruturas de Dados\n",
    "  - Árvore de aprendizado descritivo\n",
    "    - Cada nó é uma página\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"quantity\":  2,\n",
    "    \"frontier\": [],\n",
    "    \"children\": {\n",
    "        \"https://boaforma.abril.com.br\": {\n",
    "            \"quantity\":  0,\n",
    "            \"frontier\": [],\n",
    "            \"URL\": \"\",\n",
    "            \"Title\": \"\",\n",
    "            \"Text\": \"\",\n",
    "            \"Timestamp\": 000,\n",
    "            \"children\": {}\n",
    "        },\n",
    "        \"https://olhardigital.com.br\": {\n",
    "            \"quantity\":  0,\n",
    "            \"frontier\": [],\n",
    "            \"URL\": \"\",\n",
    "            \"Title\": \"\",\n",
    "            \"Text\": \"\",\n",
    "            \"Timestamp\": 000,\n",
    "            \"children\": {}\n",
    "        }.\n",
    "        \"http://www.paguemenos.com.br\": {\n",
    "            \"quantity\":  0,\n",
    "            \"frontier\": [],\n",
    "            \"URL\": \"\",\n",
    "            \"Title\": \"\",\n",
    "            \"Text\": \"\",\n",
    "            \"Timestamp\": 000,\n",
    "            \"children\": {}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "- Paralelismo\n",
    "  - Adiar o processamento de threads que passarem de algum determinado tempo de processamento.  \n",
    "  - Uma nova thread para cada nó de árvore? Não... Threads demais.\n",
    "    - Qual limite?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocódigo\n",
    "\n",
    "- [ ] Instalar bibliotecas com `requirements.txt`\n",
    "  - [ ] `pip install -r requirements.txt`\n",
    "    - [ ] BeautifulSoup4\n",
    "    - [ ] requests\n",
    "    - [ ] threading\n",
    "    - [ ] time\n",
    "    - [ ] gzip\n",
    "    - [ ] warcio\n",
    "    - [ ] json\n",
    "    - [ ] os\n",
    "- [ ] Importar bibliotecas\n",
    "- [ ] Definir os parâmetros de inicialização\n",
    "  - [ ] Path to Seeds\n",
    "  - [ ] Target Number of Webpages\n",
    "  - [ ] Debug Mode\n",
    "- [ ] Criar uma árvore inicial\n",
    "- [ ] Buscar as URL iniciais e armazenar na árvore\n",
    "- [ ] Criar o Scraper da página\n",
    "  - [ ] Definir mínima url\n",
    "  - [ ] checar se a mínima url é válida e igual a inicial\n",
    "  - [ ] Armazenar\n",
    "    - [ ] Robots.txt\n",
    "    - [ ] Sitemap\n",
    "    - [ ] HTML\n",
    "    - [ ] o título\n",
    "    - [ ] URL\n",
    "    - [ ] as 20 primeiras palavras do texto\n",
    "    - [ ] o timestamp\n",
    "    - [ ] o HTML completo\n",
    "- [ ] Criar o gerador de threads\n",
    "- [ ] Pensar em como percorrer a árvore\n",
    "  - [ ] Por enquanto seguir um dicionário simples\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentando focar no Pseudocódigo\n",
    "\n",
    "- Get Seeds\n",
    "- Store Frontier\n",
    "  1. Dicionário\n",
    "     1. Sem prioridade\n",
    "     2. Com prioridade\n",
    "  2. Árvore\n",
    "- Percorrer frontier (1: Single, 2: Threading)\n",
    "  - If new domain\n",
    "   - Pre-processing\n",
    "     - Read Robots\n",
    "       - Agents\n",
    "       - Delay\n",
    "     - Read Sitemap\n",
    "       - Recursively\n",
    "         - URL:\n",
    "           - loc: url\n",
    "           - lastmod: timestamp\n",
    "  - Get HTML\n",
    "    1. focus on delaying\n",
    "  - Parse\n",
    "  - Get Links\n",
    "  - Update Frontier\n",
    "  - Rerank\n",
    "  - new domains > outlinks > old inlinks > new inlinks\n",
    "\n",
    "---\n",
    "\n",
    "## MVP\n",
    "\n",
    "- Get Seeds\n",
    "- Store Frontier on list\n",
    "- While Frontier:\n",
    "  - Get URL\n",
    "  - Parse HTML\n",
    "  - Get Links\n",
    "  - Update Frontier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Might be needed later\n",
    "\n",
    "```python\n",
    "url = \"https://example.com/some/path/page.html\"\n",
    "parsed_url = requests.utils.urlparse(url)\n",
    "scheme = parsed_url.scheme\n",
    "domain = parsed_url.netloc\n",
    "path = parsed_url.path\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes necessários\n",
    "\n",
    "Primeiro instalaremos e importaremos os pacotes necessários para o funcionamento do crawler. Utilizou-se do arquivo `requirements.txt` para instalar as dependências do projeto. O arquivo `requirements.txt` que contém essa lista.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Installing Python packages \"\"\"\n",
    "\n",
    "# run installation with requirements.txt\n",
    "\n",
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação\n",
    "\n",
    "Os pacotes pacotes importados serão de extrema importância para o funcionamento do crawler. Abaixo estão os pacotes que foram importados e suas respectivas funções:\n",
    "\n",
    "- **BeautifulSoup4:** Utilizado para fazer o parsing do HTML e extrair informações relevantes, como o título da página e o texto visível.\n",
    "- **requests:** Usado para fazer requisições HTTP e baixar o conteúdo das páginas da web.\n",
    "- **datetime:** Usado para manipular datas e horários, especialmente para registrar o timestamp de quando a página foi baixada.\n",
    "- **warcio:** Usado para criar arquivos WARC (Web ARChive) que armazenam o conteúdo baixado de forma eficiente.\n",
    "- **os:** Usado para interagir com o sistema operacional, como criar diretórios e manipular arquivos.\n",
    "- **json:** Usado para manipular dados no formato JSON, especialmente para imprimir os resultados do crawler.\n",
    "- **gzip:** Usado para compactar os arquivos WARC, reduzindo o espaço de armazenamento necessário.\n",
    "- **threading:** Usado para criar e gerenciar threads, permitindo que o crawler baixe várias páginas simultaneamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importando as bibliotecas necessárias \"\"\"\n",
    "\n",
    "# import beautifulsoup4 as bs\n",
    "# import certifi                          # Root certificates for validating SSL/TLS (used by requests)\n",
    "# import charset_normalizer               # Used for detecting and normalizing text encodings (dependency of requests)\n",
    "# import idna                             # Internationalized domain name support (dependency of requests)\n",
    "# from protego import Protego             # Parses and enforces robots.txt rules\n",
    "import requests                         # HTTP library for making requests to web resources\n",
    "# import six                              # Compatibility layer for writing Python 2/3 code (used by many older libs)\n",
    "# import soupsieve                        # CSS selector engine for BeautifulSoup\n",
    "# import typing_extensions                # Adds backported or experimental typing features for older Python versions\n",
    "# from url_normalize import url_normalize # Normalizes URLs into a consistent format\n",
    "# import urllib3                          # Low-level HTTP library used by requests\n",
    "# import warcio                           # Library for reading and writing WARC (Web ARChive) files\n",
    "# from warcio.capture_http import capture_http # Capture HTTP requests and responses for archiving\n",
    "from warcio.warcwriter import WARCWriter # GPT is helping me with WARCing\n",
    "from warcio.statusandheaders import StatusAndHeaders\n",
    "from io import BytesIO # GPT is helping me with WARCing\n",
    "\n",
    "# JV\n",
    "import bs4 as bs # BeautifulSoup wrapper for parsing HTML and XML\n",
    "import datetime # Getting unix timestamp\n",
    "import json\n",
    "import re # Splitting strings\n",
    "import argparse # Parsing command line arguments\n",
    "import sys\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python CLI\n",
    "\n",
    "- The `argparse` module is a standard library in Python that provides a way to handle command-line arguments passed to a script. It allows you to define the expected arguments, their types, and whether they are required or optional. The module automatically generates help messages and handles errors related to argument parsing.\n",
    "- From the provided code, we can see that the `argparse` module is used to define three command-line arguments: `-s`, `-n`, and `-d`. Here's a breakdown of each argument:\n",
    "  - `-s <SEEDS>`: This argument specifies the path to a file containing a list of seed URLs. The URLs in this file will be used to initialize the crawling process.\n",
    "  - `-n <LIMIT>`: This argument specifies the target number of webpages to be crawled. The crawler will stop its execution once this target is reached.\n",
    "  - `-d`: This is an optional argument that indicates whether the crawler should run in debug mode. When this argument is provided, the crawler will print debugging information to the console as it processes each webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Simulating the python CLI arguments \"\"\"\n",
    "\n",
    "def get_args():\n",
    "    \"\"\" Set up command line arguments \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Web Crawling script\")\n",
    "    parser.add_argument('-s', '--seeds', type=str, required=True, help=\"Path to seed file\")\n",
    "    parser.add_argument('-n', '--limit', type=int, required=True, help=\"Number of pages to crawl\")\n",
    "    parser.add_argument('-d', '--debug', action='store_true', help=\"Enable debug mode\")\n",
    "    \n",
    "    if '__file__' not in globals():  # Detecta se está em um notebook\n",
    "        params = ['-s', './Seeds/seeds-2024711370.txt', '-n', '50', '-d']\n",
    "        args = parser.parse_args(params)  # Ignora args ou simula\n",
    "    else:\n",
    "        args = parser.parse_args()   # Usa normalmente no terminal\n",
    "    \n",
    "    return args\n",
    "\n",
    "ARGS = get_args()\n",
    "\n",
    "# print(f\"Arguments: {ARGS}\")  # Debugging line to check the arguments passed to the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variáveis Globais\n",
    "\n",
    "Alguns parâmetros globais foram definidos para facilitar o controle do crawler. Esses parâmetros incluem:\n",
    "\n",
    "- **ARGS:** Dicionário para armazenar os argumentos de linha de comando passados ao script\n",
    "  - **SEEDS:** Caminho para o arquivo que contém as URLs iniciais (sementes) para o crawler.\n",
    "  - **DEBUG:** Modo de depuração, que imprime informações detalhadas sobre o processo de download.\n",
    "  - **LIMIT:** Número máximo de páginas a serem baixadas.\n",
    "- **MIN_DELAY:** Tempo de espera entre as requisições para evitar sobrecarregar o servidor.\n",
    "- **MAX_THREADS:** Número máximo de threads que podem ser criadas para o download simultâneo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Code constants \"\"\"\n",
    "\n",
    "SEEDS_FILE = ARGS.seeds\n",
    "PAGES_LIMIT = ARGS.limit\n",
    "DEBUG_MODE = ARGS.debug\n",
    "MIN_DELAY = 100 # Delay in milliseconds between requests\n",
    "MAX_THREADS = 10 # Maximum number of threads to use for crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "- Here we have some helper functions that are used to perform specific tasks within the crawler. Mostly for debug purposes.\n",
    "- Those functions are:\n",
    "  - `print_json`: It prints the JSON object in a formatted way, making it easier to read and understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Pretty Print\n",
    "\n",
    "- `print_json` function is used to print JSON objects in a human-readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print_json \"\"\"\n",
    "\n",
    "def print_json(data):\n",
    "    \"\"\" Pretty prints JSON data. \"\"\"\n",
    "    print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Requester\n",
    "\n",
    "- `default_requester`: This function is used to make HTTP requests to a given URL. It handles the request and response process, including error handling and retries. The function takes the URL as an argument and returns the response content if the request is successful. If the request fails, it will retry a specified number of times before raising an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" default_requester: useful for removing try_except blocks from the main code \"\"\"\n",
    "\n",
    "def default_requester(url, timeout=5):\n",
    "    \"\"\" Default function to make a GET request to a URL. \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "        return response\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual useful functions\n",
    "\n",
    "Now we have the actual useful functions that are used to perform the main tasks of the crawler. Those functions are:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Print\n",
    "\n",
    "- `debug_print`: This function is used to print the debug information in the way that was specified in the assignment. It prints the URL, title, text, and timestamp of the crawled page in JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" debug_print: Prints the parsed URL in a readable format that is defined in the assignment. \"\"\"\n",
    "\n",
    "def debug_print(parsed_url):\n",
    "    \"\"\" Prints the parsed URL in a readable format. \"\"\"\n",
    "    debug_info = {\n",
    "        'URL': parsed_url['URL'],\n",
    "        'Title': parsed_url['Title'],\n",
    "        'Text': parsed_url['Text'],\n",
    "        'Timestamp': parsed_url['Timestamp'],\n",
    "    }\n",
    "    print_json(debug_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Seeds\n",
    "\n",
    "- `get_seeds`: This function is used to get the seeds from the file specified in the command line arguments. It reads the file and returns a list of URLs to be used as seeds for the crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get_seeds: Getting seeds from file \"\"\"\n",
    "\n",
    "def get_seeds(path='./Seeds/seeds-2024711370.txt'):\n",
    "    \"\"\" Reads all seeds from a file and returns them as a set. \"\"\"\n",
    "    seeds = set()\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#'):\n",
    "                seeds.add(line)\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Robots.txt\n",
    "\n",
    "- `parse_robots`: This function is used to parse the `robots.txt` file of a website. It extracts the user-agent and disallow rules from the file and returns them as a dictionary. This information is used to determine whether the crawler is allowed to access certain pages on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get_robots_txt: processes the contents of the robots.txt file. \"\"\"\n",
    "\n",
    "def get_robots_txt(url):\n",
    "    \"\"\" Returns the robots.txt file for a given URL. \"\"\"\n",
    "    def robots_scraping(robots_text):\n",
    "        \"\"\" Processes the robots info \"\"\"\n",
    "        # Parse the robots.txt file and extract the rules\n",
    "        rules = {\n",
    "            'crawl-delay': MIN_DELAY,\n",
    "            'user-agents': {},\n",
    "            'sitemap': [],\n",
    "            'misc': [],\n",
    "        }\n",
    "        lines = robots_text.splitlines()\n",
    "        user_agent = None\n",
    "        for line in lines:\n",
    "            line = line.strip().lower()\n",
    "            splitted_line = line.split(':', 1)\n",
    "\n",
    "            key = splitted_line[0].strip()\n",
    "            value = splitted_line[1].strip() if len(splitted_line) > 1 else ''\n",
    "            if key == 'user-agent':\n",
    "                user_agent = value\n",
    "                if user_agent not in rules['user-agents']:\n",
    "                    rules['user-agents'][user_agent] = { 'disallow': [], 'allow': []}\n",
    "            \n",
    "            elif key in ['disallow', 'allow'] and user_agent:\n",
    "                rules['user-agents'][user_agent][key].append(value)\n",
    "            elif key == 'crawl-delay' and user_agent:\n",
    "                try:\n",
    "                    rules[key] = int(value)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            elif key == 'sitemap':\n",
    "                rules[key].append(value)\n",
    "            else:\n",
    "                if len(line) > 0:\n",
    "                    rules['misc'].append(line)\n",
    "            \n",
    "        return rules\n",
    "        \n",
    "    \n",
    "    # Parse the URL to get the base domain\n",
    "    parsed_url = requests.utils.urlparse(url)\n",
    "    # print(type(parsed_url))\n",
    "    # print(dict(parsed_url))\n",
    "    robots_url = f\"{parsed_url.scheme}://{parsed_url.netloc}/robots.txt\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(robots_url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return robots_scraping(response.text)\n",
    "        else:\n",
    "            print(f\"Robots.txt not found for {url}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching robots.txt for {url}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Sitemap.xml\n",
    "\n",
    "- `parse_sitemap`: This function is used to parse the `sitemap.xml` file of a website. It extracts the URLs from the sitemap and returns them as a list. This information is used to find additional pages to crawl on the website.\n",
    "  - Possible improvements:\n",
    "    - Recursively parse the sitemap to find all URLs, including those in nested sitemaps.\n",
    "    - Add more info like the lastmod date for URL refreshing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Frontier\n",
    "\n",
    "- `update_frontier`: This function is based in the property of the `set` data structure in Python. It is used to update the frontier with new URLs. It adds all the new URLs to the frontier and prevents duplicates by using a set.\n",
    "  - Possible improvements:\n",
    "    - Use a priority queue to prioritize URLs based on their importance or relevance.\n",
    "    - Implement a more sophisticated deduplication strategy, such as normalizing URLs before adding them to the frontier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" update_frontier: Adds a new URL to the frontier. \"\"\"\n",
    "\n",
    "def update_frontier(frontier, parsed_url):\n",
    "    \"\"\" Updates the frontier with new links found in the parsed URL. \"\"\"\n",
    "    frontier.update(parsed_url['Outlinks'])\n",
    "    return frontier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse URLs\n",
    "\n",
    "- `parse_url`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" parse_url: Parses a URL and returns its components. \"\"\"\n",
    "\n",
    "def parse_url(url):\n",
    "    \"\"\" Parses a URL and returns its components. \"\"\"\n",
    "\n",
    "    def first_words(text):\n",
    "        \"\"\" Only get the 20 first words from the text (ignoring empty tokens) \"\"\"\n",
    "        # \\W+ = qualquer sequência de caracteres que não sejam letras ou números\n",
    "        words = re.split(r'\\W+', text)\n",
    "        # words = re.findall(r'\\b\\w[\\w\\'\\-]*[!?.,]?\\b', text) # Match palavras com pontuação leve grudada (.,!?, etc.)\n",
    "\n",
    "        # remove vazios resultantes de split\n",
    "        words = [word for word in words if word]\n",
    "        joined_words = ' '.join(words[:20])\n",
    "        return joined_words\n",
    "    \n",
    "    def get_timestamp():\n",
    "        \"\"\" Returns the current timestamp in seconds since 1970 \"\"\"\n",
    "        return int(datetime.datetime.now().timestamp())\n",
    "    \n",
    "    def get_new_links(soup):\n",
    "        \"\"\" Returns all new links found in the parsed HTML. \"\"\"\n",
    "        links = set()\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            if href.startswith('http'):\n",
    "                links.add(href)\n",
    "        return links\n",
    "    \n",
    "    def get_protocol_version(version):\n",
    "        \"\"\" Returns the protocol version used in the response. \"\"\"\n",
    "        protocol  = f'unknown {version}'\n",
    "        if version == 10:\n",
    "            protocol = 'HTTP/1.0'\n",
    "        elif version == 11:\n",
    "            protocol = 'HTTP/1.1'\n",
    "        elif version == 20:\n",
    "            protocol = 'HTTP/2.0'\n",
    "        return protocol\n",
    "    \n",
    "    def clean_text(text):\n",
    "        \"\"\" Cleans the text by removing excess whitespace and newlines. \"\"\"\n",
    "        cleaned_text = full_text.replace('\\t', ' ') # Converts tabs to spaces\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # Remove excess whitespace\n",
    "        cleaned_text = re.sub(r'\\n+', '\\n', cleaned_text) # Convert multiple newlines to a single newline\n",
    "        return cleaned_text\n",
    "    \n",
    "    base_parsed_url = { 'URL': url, 'Title': None, 'Text': None, 'Timestamp': None }\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        base_parsed_url['Response'] = response\n",
    "        mime = response.headers.get('Content-Type', '').split(';')[0]\n",
    "\n",
    "        status_code_200 = response.status_code == 200\n",
    "        is_HTML = mime == 'text/html'\n",
    "        if status_code_200 and is_HTML:\n",
    "            soup = bs.BeautifulSoup(response.content, 'html.parser')\n",
    "            full_text = soup.get_text()\n",
    "            cleaned_text = clean_text(full_text)\n",
    "            # print(cleaned_text)\n",
    "            # print(response.raw.version)\n",
    "            \n",
    "            base_parsed_url['Title'] = soup.title.string if soup.title else None\n",
    "            base_parsed_url['Text'] = first_words(full_text)\n",
    "            base_parsed_url['Timestamp'] = get_timestamp()\n",
    "            \n",
    "            base_parsed_url['Outlinks'] = get_new_links(soup)\n",
    "            base_parsed_url['Full_Text'] = cleaned_text\n",
    "            base_parsed_url['Headers'] = response.headers\n",
    "            base_parsed_url['Raw'] = response.raw\n",
    "            base_parsed_url['Status_Code'] = response.status_code\n",
    "            base_parsed_url['Protocol'] = get_protocol_version(response.raw.version)\n",
    "            \n",
    "    except requests.RequestException as e:\n",
    "        # Add debug mode later\n",
    "        print(f'Error parsing URL {url}: {e}')\n",
    "    return base_parsed_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store WARC\n",
    "\n",
    "- `store_warc`: This function is used to store the crawled pages in WARC format. It creates a WARC file and writes the HTML content of the crawled page to it. It also compresses the file using gzip to reduce storage costs.\n",
    "  - Needed improvements:\n",
    "    - Limit the number of pages stored in each WARC file to 1000, as specified in the assignment.\n",
    "  - Possible improvements:\n",
    "    - Reduce the size of the WARC file by removing unnecessary metadata or compressing the HTML content further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" store_warc: Stores the parsed URL in a WARC file. \"\"\"\n",
    "\n",
    "def store_warc(parsed_url):\n",
    "    \"\"\" Stores the parsed URL in a WARC file. \"\"\"\n",
    "    is_compressed = False\n",
    "    output_path = 'output.warc'\n",
    "    if is_compressed:\n",
    "        output_path += '.gz'\n",
    "\n",
    "    headers = StatusAndHeaders(\n",
    "        statusline=str(parsed_url['Status_Code']),\n",
    "        headers={},\n",
    "        # headers=parsed_url['Headers'].items(), # Mais completo, mas poluído.\n",
    "        protocol=parsed_url['Protocol'],\n",
    "    )\n",
    "\n",
    "    with open(output_path, 'ab') as output:  # ab = Append and Binary mode.\n",
    "        # gzip = True makes it automatically compressed.\n",
    "        writer = WARCWriter(output, gzip=is_compressed)\n",
    "        record = writer.create_warc_record(\n",
    "            uri=parsed_url['URL'],\n",
    "            record_type='response',\n",
    "            payload=BytesIO(parsed_url['Full_Text'].encode('utf-8')),\n",
    "            # payload=parsed_url['Raw'],\n",
    "            http_headers=headers,\n",
    "        )\n",
    "        writer.write_record(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get_sitemap: processes the contents of the sitemap.xml file. \"\"\"\n",
    "\n",
    "def get_sitemap(url, robots_info=None):\n",
    "    def parse_sitemap(sitemap_url):\n",
    "        \"\"\" Processes the sitemap XML and extracts URLs info \"\"\"\n",
    "        response = default_requester(sitemap_url)\n",
    "        if response is None:\n",
    "            return [set(), set()]\n",
    "        sitemap_text = response.text\n",
    "        soup = bs.BeautifulSoup(sitemap_text, 'xml')\n",
    "        urls = list()\n",
    "        xmls = list()\n",
    "        \n",
    "        # Extract URLs from the sitemap\n",
    "        for url in soup.find_all('url'):\n",
    "            loc = url.find('loc')\n",
    "            urls.append(loc.text.strip()) if loc else None\n",
    "        for sitemap in soup.find_all('sitemap'):\n",
    "            loc = sitemap.find('loc')\n",
    "            xmls.append(loc.text.strip()) if loc else None\n",
    "        return [xmls, urls]\n",
    "    \n",
    "    def traverse_sitemaps(sitemap_info):\n",
    "        sitemap_queue = deque(sitemap_info['sitemap_urls'])\n",
    "        # index = 0\n",
    "        while sitemap_queue:\n",
    "            sitemap_url = sitemap_queue.popleft()\n",
    "            [nested, pages] = parse_sitemap(sitemap_url)\n",
    "            sitemap_queue.extend(nested)  # adiciona os sitemaps internos na fila\n",
    "            sitemap_info['sitemap_urls'].extend(nested)  # adiciona os sitemaps internos na lista de sitemaps\n",
    "            sitemap_info['found_urls'].extend(pages)\n",
    "            \n",
    "            # index += 1\n",
    "            # msg = f'{index}/{len(sitemap_info[\"sitemap_urls\"])}\\t {sitemap_url}: pages: {len(sitemap_info[\"found_urls\"])}'\n",
    "            # print(msg)\n",
    "            # print_json({'sitemaps': len(sitemap_info['sitemap_urls']), 'pages': len(sitemap_info['found_urls'])})\n",
    "\n",
    "        return sitemap_info\n",
    "    \n",
    "    if len(robots_info['sitemap']) == 0:\n",
    "        parsed_url = requests.utils.urlparse(url)\n",
    "        sitemap_url = f\"{parsed_url.scheme}://{parsed_url.netloc}/sitemap.xml\"\n",
    "        robots_info['sitemap'] = [sitemap_url]\n",
    "\n",
    "    sitemap_info = {'found_urls': [], 'sitemap_urls': robots_info['sitemap'] }\n",
    "    \n",
    "    sitemap_info = traverse_sitemaps(sitemap_info)\n",
    "\n",
    "    # print_json(sitemap_info)\n",
    "\n",
    "    return sitemap_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "\n",
    "- `main`: This is the main function of the crawler. It initializes the crawler, reads the command line arguments, and starts the crawling process. It also handles the threading and manages the download rate to avoid overloading the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/407\t https://olhardigital.com.br/sitemap.xml: pages: 0\n",
      "2/407\t https://olhardigital.com.br/sitemap/sitemap_root.xml: pages: 3\n",
      "3/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-04_1.xml: pages: 953\n",
      "4/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-04_2.xml: pages: 1774\n",
      "5/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-03_1.xml: pages: 2724\n",
      "6/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-03_2.xml: pages: 3674\n",
      "7/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-03_3.xml: pages: 3687\n",
      "8/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-02_1.xml: pages: 4637\n",
      "9/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-02_2.xml: pages: 5551\n",
      "10/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-01_1.xml: pages: 6501\n",
      "11/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-01_2.xml: pages: 7451\n",
      "12/407\t https://olhardigital.com.br/sitemap/sitemap_post_2025-01_3.xml: pages: 7777\n",
      "13/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-12_1.xml: pages: 8727\n",
      "14/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-12_2.xml: pages: 9482\n",
      "15/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-11_1.xml: pages: 10432\n",
      "16/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-11_2.xml: pages: 11230\n",
      "17/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-10_1.xml: pages: 12180\n",
      "18/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-10_2.xml: pages: 13130\n",
      "19/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-10_3.xml: pages: 13199\n",
      "20/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-09_1.xml: pages: 14149\n",
      "21/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-09_2.xml: pages: 15044\n",
      "22/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-08_1.xml: pages: 15994\n",
      "23/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-08_2.xml: pages: 16913\n",
      "24/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-07_1.xml: pages: 17863\n",
      "25/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-07_2.xml: pages: 18810\n",
      "26/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-06_1.xml: pages: 19760\n",
      "27/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-06_2.xml: pages: 20710\n",
      "28/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-06_3.xml: pages: 20757\n",
      "29/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-05_1.xml: pages: 21707\n",
      "30/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-05_2.xml: pages: 22657\n",
      "31/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-05_3.xml: pages: 22972\n",
      "32/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-04_1.xml: pages: 23922\n",
      "33/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-04_2.xml: pages: 24872\n",
      "34/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-04_3.xml: pages: 25100\n",
      "35/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-03_1.xml: pages: 26050\n",
      "36/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-03_2.xml: pages: 27000\n",
      "37/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-03_3.xml: pages: 27059\n",
      "38/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-02_1.xml: pages: 28009\n",
      "39/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-02_2.xml: pages: 28900\n",
      "40/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-01_1.xml: pages: 29850\n",
      "41/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-01_2.xml: pages: 30800\n",
      "42/407\t https://olhardigital.com.br/sitemap/sitemap_post_2024-01_3.xml: pages: 30911\n",
      "43/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-12_1.xml: pages: 31861\n",
      "44/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-12_2.xml: pages: 32808\n",
      "45/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-11_1.xml: pages: 33758\n",
      "46/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-11_2.xml: pages: 34708\n",
      "47/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-11_3.xml: pages: 34756\n",
      "48/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-10_1.xml: pages: 35706\n",
      "49/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-10_2.xml: pages: 36656\n",
      "50/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-10_3.xml: pages: 36858\n",
      "51/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-09_1.xml: pages: 37808\n",
      "52/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-09_2.xml: pages: 38758\n",
      "53/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-09_3.xml: pages: 38864\n",
      "54/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-08_1.xml: pages: 39814\n",
      "55/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-08_2.xml: pages: 40764\n",
      "56/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-08_3.xml: pages: 41044\n",
      "57/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-07_1.xml: pages: 41994\n",
      "58/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-07_2.xml: pages: 42944\n",
      "59/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-07_3.xml: pages: 42965\n",
      "60/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-06_1.xml: pages: 43915\n",
      "61/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-06_2.xml: pages: 44550\n",
      "62/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-05_1.xml: pages: 45500\n",
      "63/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-05_2.xml: pages: 46221\n",
      "64/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-04_1.xml: pages: 47171\n",
      "65/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-04_2.xml: pages: 47545\n",
      "66/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-03_1.xml: pages: 48495\n",
      "67/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-03_2.xml: pages: 48955\n",
      "68/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-02_1.xml: pages: 49905\n",
      "69/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-02_2.xml: pages: 50009\n",
      "70/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-01_1.xml: pages: 50959\n",
      "71/407\t https://olhardigital.com.br/sitemap/sitemap_post_2023-01_2.xml: pages: 51426\n",
      "72/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-12_1.xml: pages: 52376\n",
      "73/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-12_2.xml: pages: 53093\n",
      "74/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-11_1.xml: pages: 54043\n",
      "75/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-11_2.xml: pages: 54993\n",
      "76/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-11_3.xml: pages: 55943\n",
      "77/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-11_4.xml: pages: 56248\n",
      "78/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-10_1.xml: pages: 57198\n",
      "79/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-10_2.xml: pages: 57992\n",
      "80/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-09_1.xml: pages: 58942\n",
      "81/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-09_2.xml: pages: 59584\n",
      "82/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-08_1.xml: pages: 60534\n",
      "83/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-08_2.xml: pages: 61293\n",
      "84/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-07_1.xml: pages: 62243\n",
      "85/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-07_2.xml: pages: 62767\n",
      "86/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-06_1.xml: pages: 63717\n",
      "87/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-06_2.xml: pages: 64365\n",
      "88/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-05_1.xml: pages: 65315\n",
      "89/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-05_2.xml: pages: 65934\n",
      "90/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-04_1.xml: pages: 66884\n",
      "91/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-04_2.xml: pages: 67688\n",
      "92/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-03_1.xml: pages: 68638\n",
      "93/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-03_2.xml: pages: 69474\n",
      "94/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-02_1.xml: pages: 70424\n",
      "95/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-02_2.xml: pages: 71076\n",
      "96/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-01_1.xml: pages: 72026\n",
      "97/407\t https://olhardigital.com.br/sitemap/sitemap_post_2022-01_2.xml: pages: 72695\n",
      "98/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-12_1.xml: pages: 73645\n",
      "99/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-12_2.xml: pages: 74260\n",
      "100/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-11_1.xml: pages: 75210\n",
      "101/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-11_2.xml: pages: 75934\n",
      "102/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-10_1.xml: pages: 76884\n",
      "103/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-10_2.xml: pages: 77834\n",
      "104/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-10_3.xml: pages: 78308\n",
      "105/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-09_1.xml: pages: 79258\n",
      "106/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-09_2.xml: pages: 80208\n",
      "107/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-09_3.xml: pages: 80303\n",
      "108/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-08_1.xml: pages: 81253\n",
      "109/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-08_2.xml: pages: 82203\n",
      "110/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-08_3.xml: pages: 82456\n",
      "111/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-07_1.xml: pages: 83406\n",
      "112/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-07_2.xml: pages: 84330\n",
      "113/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-06_1.xml: pages: 85280\n",
      "114/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-06_2.xml: pages: 86214\n",
      "115/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-05_1.xml: pages: 87164\n",
      "116/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-05_2.xml: pages: 88025\n",
      "117/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-04_1.xml: pages: 88975\n",
      "118/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-04_2.xml: pages: 89769\n",
      "119/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-03_1.xml: pages: 90719\n",
      "120/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-03_2.xml: pages: 91399\n",
      "121/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-02_1.xml: pages: 92349\n",
      "122/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-02_2.xml: pages: 92775\n",
      "123/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-01_1.xml: pages: 93725\n",
      "124/407\t https://olhardigital.com.br/sitemap/sitemap_post_2021-01_2.xml: pages: 93991\n",
      "125/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-12.xml: pages: 94938\n",
      "126/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-11_1.xml: pages: 95888\n",
      "127/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-11_2.xml: pages: 95988\n",
      "128/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-10_1.xml: pages: 96938\n",
      "129/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-10_2.xml: pages: 97471\n",
      "130/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-09_1.xml: pages: 98421\n",
      "131/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-09_2.xml: pages: 99024\n",
      "132/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-08_1.xml: pages: 99974\n",
      "133/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-08_2.xml: pages: 100224\n",
      "134/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-07_1.xml: pages: 101174\n",
      "135/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-07_2.xml: pages: 101607\n",
      "136/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-06_1.xml: pages: 102557\n",
      "137/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-06_2.xml: pages: 102847\n",
      "138/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-05_1.xml: pages: 103797\n",
      "139/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-05_2.xml: pages: 104070\n",
      "140/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-04_1.xml: pages: 105020\n",
      "141/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-04_2.xml: pages: 105325\n",
      "142/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-03_1.xml: pages: 106275\n",
      "143/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-03_2.xml: pages: 106598\n",
      "144/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-02_1.xml: pages: 107548\n",
      "145/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-02_2.xml: pages: 107798\n",
      "146/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-01_1.xml: pages: 108748\n",
      "147/407\t https://olhardigital.com.br/sitemap/sitemap_post_2020-01_2.xml: pages: 108983\n",
      "148/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-12_1.xml: pages: 109933\n",
      "149/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-12_2.xml: pages: 110007\n",
      "150/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-11_1.xml: pages: 110957\n",
      "151/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-11_2.xml: pages: 111205\n",
      "152/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-10_1.xml: pages: 112155\n",
      "153/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-10_2.xml: pages: 112493\n",
      "154/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-09_1.xml: pages: 113443\n",
      "155/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-09_2.xml: pages: 113514\n",
      "156/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-08_1.xml: pages: 114464\n",
      "157/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-08_2.xml: pages: 114547\n",
      "158/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-07_1.xml: pages: 115497\n",
      "159/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-07_2.xml: pages: 115593\n",
      "160/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-06.xml: pages: 116528\n",
      "161/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-05_1.xml: pages: 117478\n",
      "162/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-05_2.xml: pages: 117511\n",
      "163/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-04_1.xml: pages: 118461\n",
      "164/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-04_2.xml: pages: 118489\n",
      "165/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-03.xml: pages: 119344\n",
      "166/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-02.xml: pages: 120141\n",
      "167/407\t https://olhardigital.com.br/sitemap/sitemap_post_2019-01.xml: pages: 120725\n",
      "168/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-12.xml: pages: 121244\n",
      "169/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-11.xml: pages: 121841\n",
      "170/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-10.xml: pages: 122467\n",
      "171/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-09.xml: pages: 122956\n",
      "172/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-08.xml: pages: 123465\n",
      "173/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-07.xml: pages: 123986\n",
      "174/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-06.xml: pages: 124595\n",
      "175/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-05.xml: pages: 125180\n",
      "176/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-04.xml: pages: 125681\n",
      "177/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-03.xml: pages: 126195\n",
      "178/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-02.xml: pages: 126675\n",
      "179/407\t https://olhardigital.com.br/sitemap/sitemap_post_2018-01.xml: pages: 127241\n",
      "180/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-12.xml: pages: 127684\n",
      "181/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-11.xml: pages: 128261\n",
      "182/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-10.xml: pages: 128866\n",
      "183/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-09.xml: pages: 129395\n",
      "184/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-08.xml: pages: 130034\n",
      "185/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-07.xml: pages: 130624\n",
      "186/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-06.xml: pages: 131308\n",
      "187/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-05.xml: pages: 131990\n",
      "188/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-04.xml: pages: 132550\n",
      "189/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-03.xml: pages: 133168\n",
      "190/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-02.xml: pages: 133726\n",
      "191/407\t https://olhardigital.com.br/sitemap/sitemap_post_2017-01.xml: pages: 134313\n",
      "192/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-12.xml: pages: 134879\n",
      "193/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-11.xml: pages: 135538\n",
      "194/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-10.xml: pages: 136253\n",
      "195/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-09.xml: pages: 137000\n",
      "196/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-08.xml: pages: 137794\n",
      "197/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-07.xml: pages: 138538\n",
      "198/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-06.xml: pages: 139400\n",
      "199/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-05.xml: pages: 140296\n",
      "200/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-04.xml: pages: 141075\n",
      "201/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-03.xml: pages: 141927\n",
      "202/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-02.xml: pages: 142650\n",
      "203/407\t https://olhardigital.com.br/sitemap/sitemap_post_2016-01.xml: pages: 143273\n",
      "204/407\t https://olhardigital.com.br/sitemap/sitemap_post_2015-12.xml: pages: 143853\n",
      "205/407\t https://olhardigital.com.br/sitemap/sitemap_post_2015-11.xml: pages: 144499\n",
      "206/407\t https://olhardigital.com.br/sitemap/sitemap_post_2015-10.xml: pages: 145170\n",
      "207/407\t https://olhardigital.com.br/sitemap/sitemap_post_2015-09.xml: pages: 145184\n",
      "208/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2025-02.xml: pages: 145226\n",
      "209/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2025-01.xml: pages: 145304\n",
      "210/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2024-12.xml: pages: 145305\n",
      "211/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2024-11.xml: pages: 145306\n",
      "212/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2024-09.xml: pages: 145308\n",
      "213/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2024-04.xml: pages: 145399\n",
      "214/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2024-03.xml: pages: 145560\n",
      "215/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2024-02.xml: pages: 145733\n",
      "216/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2024-01.xml: pages: 145863\n",
      "217/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2023-12.xml: pages: 145864\n",
      "218/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2023-09.xml: pages: 145874\n",
      "219/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2023-08.xml: pages: 145879\n",
      "220/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2023-04.xml: pages: 146008\n",
      "221/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2023-03.xml: pages: 146166\n",
      "222/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2023-02.xml: pages: 146333\n",
      "223/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2023-01.xml: pages: 146478\n",
      "224/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2022-04.xml: pages: 146624\n",
      "225/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2022-03.xml: pages: 146823\n",
      "226/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2022-02.xml: pages: 147014\n",
      "227/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2022-01.xml: pages: 147192\n",
      "228/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2021-04.xml: pages: 147357\n",
      "229/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2021-03.xml: pages: 147527\n",
      "230/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2021-02.xml: pages: 147717\n",
      "231/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2021-01.xml: pages: 147889\n",
      "232/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2020-04.xml: pages: 148037\n",
      "233/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2020-03.xml: pages: 148221\n",
      "234/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2020-02.xml: pages: 148386\n",
      "235/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2020-01.xml: pages: 148498\n",
      "236/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2019-04.xml: pages: 148618\n",
      "237/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2019-03.xml: pages: 148800\n",
      "238/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2019-02.xml: pages: 148940\n",
      "239/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2019-01.xml: pages: 149080\n",
      "240/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2018-04.xml: pages: 149225\n",
      "241/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2018-03.xml: pages: 149361\n",
      "242/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2018-02.xml: pages: 149501\n",
      "243/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2018-01.xml: pages: 149622\n",
      "244/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2017-04.xml: pages: 149718\n",
      "245/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2017-03.xml: pages: 149836\n",
      "246/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2017-02.xml: pages: 149966\n",
      "247/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2017-01.xml: pages: 150042\n",
      "248/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2016-04.xml: pages: 150117\n",
      "249/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2016-03.xml: pages: 150253\n",
      "250/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2016-02.xml: pages: 150347\n",
      "251/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2016-01.xml: pages: 150418\n",
      "252/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2015-05.xml: pages: 150472\n",
      "253/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2015-04.xml: pages: 150524\n",
      "254/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2015-03.xml: pages: 150579\n",
      "255/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2015-02.xml: pages: 150646\n",
      "256/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2015-01.xml: pages: 150720\n",
      "257/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2014-05.xml: pages: 150735\n",
      "258/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2014-04.xml: pages: 150764\n",
      "259/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2014-03.xml: pages: 150823\n",
      "260/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2014-02.xml: pages: 150890\n",
      "261/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2014-01.xml: pages: 150955\n",
      "262/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2013-05.xml: pages: 150990\n",
      "263/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2013-04.xml: pages: 151028\n",
      "264/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2013-03.xml: pages: 151051\n",
      "265/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2013-02.xml: pages: 151088\n",
      "266/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2013-01.xml: pages: 151131\n",
      "267/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2012-04.xml: pages: 151177\n",
      "268/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2012-03.xml: pages: 151215\n",
      "269/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2012-02.xml: pages: 151247\n",
      "270/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2012-01.xml: pages: 151284\n",
      "271/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2011-04.xml: pages: 151333\n",
      "272/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2011-03.xml: pages: 151373\n",
      "273/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2011-02.xml: pages: 151396\n",
      "274/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2011-01.xml: pages: 151441\n",
      "275/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2010-04.xml: pages: 151484\n",
      "276/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2010-03.xml: pages: 151542\n",
      "277/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2010-02.xml: pages: 151593\n",
      "278/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2010-01.xml: pages: 151627\n",
      "279/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2009-04.xml: pages: 151657\n",
      "280/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2009-03.xml: pages: 151731\n",
      "281/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2009-02.xml: pages: 151773\n",
      "282/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2009-01.xml: pages: 151800\n",
      "283/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2008-04.xml: pages: 151878\n",
      "284/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2008-03.xml: pages: 151948\n",
      "285/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2008-02.xml: pages: 151999\n",
      "286/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2008-01.xml: pages: 152032\n",
      "287/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2007-04.xml: pages: 152099\n",
      "288/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2007-03.xml: pages: 152139\n",
      "289/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2007-02.xml: pages: 152220\n",
      "290/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2007-01.xml: pages: 152269\n",
      "291/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2006-04.xml: pages: 152353\n",
      "292/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2006-03.xml: pages: 152428\n",
      "293/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2006-02.xml: pages: 152501\n",
      "294/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2006-01.xml: pages: 152552\n",
      "295/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2005-04.xml: pages: 152653\n",
      "296/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2005-03.xml: pages: 152713\n",
      "297/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2005-02.xml: pages: 152778\n",
      "298/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2005-01.xml: pages: 152810\n",
      "299/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2004-04.xml: pages: 152910\n",
      "300/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2004-03.xml: pages: 152961\n",
      "301/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2004-02.xml: pages: 153012\n",
      "302/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2004-01.xml: pages: 153035\n",
      "Error fetching https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2003-04.xml: HTTPSConnectionPool(host='olhardigital.com.br', port=443): Max retries exceeded with url: /sitemap/sitemap_ficha-tecnica_2003-04.xml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000024E8E219A90>, 'Connection to olhardigital.com.br timed out. (connect timeout=10)'))\n",
      "303/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2003-04.xml: pages: 153035\n",
      "304/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2003-03.xml: pages: 153073\n",
      "305/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2003-02.xml: pages: 153109\n",
      "306/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2003-01.xml: pages: 153126\n",
      "307/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2002-04.xml: pages: 153157\n",
      "308/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2002-03.xml: pages: 153169\n",
      "309/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2002-02.xml: pages: 153198\n",
      "310/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2002-01.xml: pages: 153206\n",
      "311/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2001-04.xml: pages: 153226\n",
      "312/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2001-03.xml: pages: 153244\n",
      "313/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2001-02.xml: pages: 153258\n",
      "314/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2001-01.xml: pages: 153262\n",
      "315/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2000-04.xml: pages: 153283\n",
      "316/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2000-03.xml: pages: 153290\n",
      "317/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2000-02.xml: pages: 153295\n",
      "318/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_2000-01.xml: pages: 153296\n",
      "319/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_1999-04.xml: pages: 153300\n",
      "320/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_1999-03.xml: pages: 153303\n",
      "321/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_1999-02.xml: pages: 153304\n",
      "322/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_1999-01.xml: pages: 153306\n",
      "323/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_1998-04.xml: pages: 153307\n",
      "324/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_1997-04.xml: pages: 153311\n",
      "325/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-tecnica_1995-01.xml: pages: 153359\n",
      "326/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2025-04.xml: pages: 153467\n",
      "Error fetching https://olhardigital.com.br/sitemap/sitemap_web-story_2025-03.xml: HTTPSConnectionPool(host='olhardigital.com.br', port=443): Max retries exceeded with url: /sitemap/sitemap_web-story_2025-03.xml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000024E8E51F650>, 'Connection to olhardigital.com.br timed out. (connect timeout=10)'))\n",
      "327/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2025-03.xml: pages: 153467\n",
      "328/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2025-02.xml: pages: 153584\n",
      "329/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2025-01.xml: pages: 153675\n",
      "330/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-12.xml: pages: 153709\n",
      "331/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-11.xml: pages: 153751\n",
      "332/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-10.xml: pages: 153796\n",
      "333/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-09.xml: pages: 153833\n",
      "334/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-08.xml: pages: 153869\n",
      "335/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-07.xml: pages: 153901\n",
      "336/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-06.xml: pages: 153926\n",
      "337/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-05.xml: pages: 153933\n",
      "338/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-04.xml: pages: 153942\n",
      "339/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-03.xml: pages: 153951\n",
      "340/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-02.xml: pages: 153954\n",
      "341/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2024-01.xml: pages: 153959\n",
      "342/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-12.xml: pages: 153964\n",
      "343/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-11.xml: pages: 153968\n",
      "344/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-10.xml: pages: 153974\n",
      "345/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-09.xml: pages: 153981\n",
      "346/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-08.xml: pages: 153990\n",
      "347/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-07.xml: pages: 153998\n",
      "348/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-06.xml: pages: 154004\n",
      "349/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-05.xml: pages: 154007\n",
      "350/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-04.xml: pages: 154009\n",
      "351/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-03.xml: pages: 154012\n",
      "352/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-02.xml: pages: 154015\n",
      "353/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2023-01.xml: pages: 154041\n",
      "354/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2022-12.xml: pages: 154082\n",
      "355/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2022-11.xml: pages: 154124\n",
      "356/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2022-09.xml: pages: 154129\n",
      "357/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2022-08.xml: pages: 154130\n",
      "358/407\t https://olhardigital.com.br/sitemap/sitemap_web-story_2021-12.xml: pages: 154131\n",
      "359/407\t https://olhardigital.com.br/sitemap/sitemap_page_2025-03.xml: pages: 154133\n",
      "360/407\t https://olhardigital.com.br/sitemap/sitemap_page_2025-02.xml: pages: 154134\n",
      "361/407\t https://olhardigital.com.br/sitemap/sitemap_page_2025-01.xml: pages: 154139\n",
      "362/407\t https://olhardigital.com.br/sitemap/sitemap_page_2024-11.xml: pages: 154141\n",
      "363/407\t https://olhardigital.com.br/sitemap/sitemap_page_2024-01.xml: pages: 154142\n",
      "364/407\t https://olhardigital.com.br/sitemap/sitemap_page_2023-09.xml: pages: 154143\n",
      "365/407\t https://olhardigital.com.br/sitemap/sitemap_page_2021-03.xml: pages: 154144\n",
      "366/407\t https://olhardigital.com.br/sitemap/sitemap_page_2020-12.xml: pages: 154145\n",
      "367/407\t https://olhardigital.com.br/sitemap/sitemap_page_2020-11.xml: pages: 154146\n",
      "368/407\t https://olhardigital.com.br/sitemap/sitemap_category_5.xml: pages: 154147\n",
      "369/407\t https://olhardigital.com.br/sitemap/sitemap_category_A-W.xml: pages: 154199\n",
      "370/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_0-9.xml: pages: 154282\n",
      "371/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_A(1).xml: pages: 155232\n",
      "372/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_A(2).xml: pages: 156034\n",
      "373/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_B.xml: pages: 156945\n",
      "374/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_C(1).xml: pages: 157895\n",
      "375/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_C(2).xml: pages: 158845\n",
      "376/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_C(3).xml: pages: 159147\n",
      "377/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_D(1).xml: pages: 160097\n",
      "378/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_D(2).xml: pages: 160184\n",
      "379/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_E(1).xml: pages: 161134\n",
      "380/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_E(2).xml: pages: 161190\n",
      "381/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_F.xml: pages: 162098\n",
      "382/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_G.xml: pages: 163043\n",
      "383/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_H.xml: pages: 163536\n",
      "384/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_I.xml: pages: 164302\n",
      "385/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_J-K.xml: pages: 164859\n",
      "386/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_L.xml: pages: 165608\n",
      "387/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_M(1).xml: pages: 166558\n",
      "388/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_M(2).xml: pages: 167270\n",
      "389/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_N.xml: pages: 167911\n",
      "390/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_O.xml: pages: 168433\n",
      "391/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_P(1).xml: pages: 169383\n",
      "392/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_P(2).xml: pages: 169996\n",
      "393/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_Q.xml: pages: 170099\n",
      "394/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_R(1).xml: pages: 171049\n",
      "395/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_R(2).xml: pages: 171063\n",
      "396/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_S(1).xml: pages: 172013\n",
      "397/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_S(2).xml: pages: 172614\n",
      "398/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_T(1).xml: pages: 173564\n",
      "399/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_T(2).xml: pages: 173738\n",
      "400/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_U.xml: pages: 174126\n",
      "401/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_V-W.xml: pages: 175050\n",
      "402/407\t https://olhardigital.com.br/sitemap/sitemap_post_tag_X-Z.xml: pages: 175341\n",
      "403/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-marca.xml: pages: 175481\n",
      "404/407\t https://olhardigital.com.br/sitemap/sitemap_ficha-categoria.xml: pages: 175482\n",
      "405/407\t https://olhardigital.com.br/sitemap/sitemap_web_story_category.xml: pages: 175484\n",
      "406/407\t https://olhardigital.com.br/sitemap/sitemap_web_story_tag_3-4.xml: pages: 175486\n",
      "407/407\t https://olhardigital.com.br/sitemap/sitemap_web_story_tag_A-Z.xml: pages: 176358\n"
     ]
    }
   ],
   "source": [
    "def debug_sitemap():\n",
    "    url = \"https://olhardigital.com.br\"\n",
    "    robots_info = get_robots_txt(url)\n",
    "    robots_info['sitemap'] = []  # Clear the sitemap list to force fetching\n",
    "    result = get_sitemap(url, robots_info)\n",
    "\n",
    "debug_sitemap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Runnning MVP \"\"\"\n",
    "\n",
    "def main():\n",
    "    \"\"\" Main function to run the MVP. \"\"\"\n",
    "    frontier = get_seeds(SEEDS_FILE)\n",
    "    shallow_frontier = frontier.copy()\n",
    "    for url in shallow_frontier:\n",
    "        robots_info = get_robots_txt(url)\n",
    "        # print_json(robots_info)\n",
    "        sitemap_info = get_sitemap(url, robots_info)\n",
    "        print_json(sitemap_info)\n",
    "        # parsed_url = parse_url(url)\n",
    "        if DEBUG_MODE:\n",
    "            pass\n",
    "            # debug_print(parsed_url)\n",
    "        # print(len(parsed_url['Outlinks']), url)\n",
    "        # frontier = update_frontier(frontier, parsed_url)\n",
    "        # print(frontier)\n",
    "        # store_warc(parsed_url)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(results['found_urls']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
