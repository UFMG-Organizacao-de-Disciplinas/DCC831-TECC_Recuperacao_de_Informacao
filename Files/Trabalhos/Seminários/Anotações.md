# Seminários

## Enunciado

Caros alunos,

Conforme nosso plano de ensino, nesta reta final (a princípio, 16/06 e 18/06, a depender do número de apresentações), teremos seminários para discussão de artigos recentes na área de recuperação de informação.

Para os seminários, cada grupo de 3-4 alunos deverá escolher um artigo para apresentação e discussão durante a aula. O grupo pode escolher preparar uma nova apresentação ou utilizar os slides originais dos autores do artigo escolhido, caso estejam disponíveis. Podem ser escolhidos artigos completos (8-12 páginas) sobre recuperação de informação publicados em qualquer uma das seguintes conferências:

- [CIKM 2024](https://dblp.org/db/conf/cikm/cikm2024.html)
- [KDD 2024](https://dblp.org/db/conf/kdd/kdd2024.html)
- [SIGIR 2024](https://dblp.org/db/conf/sigir/sigir2024.html)
- [WSDM 2025](https://dblp.org/db/conf/wsdm/wsdm2025.html)
- [WWW 2025](https://dblp.org/db/conf/www/www2025.html)

Os grupos deverão informar o artigo escolhido para apresentação até quarta, 04/06, na seguinte planilha: <http://bit.ly/3Z9VBiC>.

A ordem de apresentações será divulgada em seguida.

Rodrygo

## Anotações

- São papers avançados. Não é esperado que entendamos completamente, mas que consigamos expressar o que aprendemos pro restante da sala.
- Por ser em grupo é com o intuito de reduzir o número de apresentações e discutamos entre nós.
- Pode usar o GPT. O objetivo é entender.
- Estrutura:
  - Recomenda encontrar os slides dos autores.
  - Tentar fazer algo em tornar a apresentação mais didática.
  - A mesma dificuldade que teremos lendo, será a mesma que os outros terão vendo a apresentação.
  - Mesmo o autor do paper teve limitação de tempo para apresentar.
  - Como foi a avaliação do paper?
  - É uma mini aula em um tempo reduzido de um tempo avançado.

## Escolhendo artigo

| Interesse |  Score | Note                   | Título                                                                                                   | Link                                               | # Pages | Outros                             |
| --------: | -----: | ---------------------- | :------------------------------------------------------------------------------------------------------- | :------------------------------------------------- | ------: | ---------------------------------- |
|         6 | 9 (OK) | LTR stuff              | An E-Commerce Dataset Revealing Variations during Sales                                                  | [Link 9](https://doi.org/10.1145/3626772.3657870)  |       9 |                                    |
|         4 | 9 (OK) | Has potential          | The Power of Noise: Redefining Retrieval for RAG Systems                                                 | [Link 10](https://doi.org/10.1145/3626772.3657834) |      10 |                                    |
|         6 | 8 (OK) | Quite consistent       | Generative Retrieval via Term Set Generation                                                             | [Link 10](https://doi.org/10.1145/3626772.3657797) |      10 |                                    |
|         7 |  9 (?) | More RecSys then RI    | EditKG: Editing Knowledge Graph for Recommendation                                                       | [Link 10](https://doi.org/10.1145/3626772.3657723) |      10 |                                    |
|         8 |  8 (?) | Not quite technical    | Large Language Models and Future of Information Retrieval: Opportunities and Challenges                  | [Link 9](https://doi.org/10.1145/3626772.3657848)  |       9 | [YT](https://youtu.be/fTdVWiancgI) |
|         9 |  5 (~) | Not so IR related      | YAGO 4.5: A Large and Clean Knowledge Base with a Rich Taxonomy                                          | [Link 9](https://doi.org/10.1145/3626772.3657876)  |       9 | [YT](https://youtu.be/l-t6_j56MlE) |
|         3 |  4 (~) | Quite untasteful       | Evaluating Generative Ad Hoc Information Retrieval                                                       | [Link 13](https://doi.org/10.1145/3626772.3657849) |      13 |                                    |
|         8 |  3 (X) | Seems like an aux tool | Browsing and Searching Metadata of TREC                                                                  | [Link 10](https://doi.org/10.1145/3626772.3657873) |      10 | [YT](https://youtu.be/Hg87xdGf2yE) |
|         5 |        |                        | Explainability for Transparent Conversational Information-Seeking                                        | [Link 10](https://doi.org/10.1145/3626772.3657768) |      10 |                                    |
|         5 |        |                        | JDivPS: A Diversified Product Search Dataset                                                             | [Link 9](https://doi.org/10.1145/3626772.3657888)  |       9 |                                    |
|         2 |        |                        | Enhancing Sequential Recommenders with Augmented Knowledge from Aligned Large Language Models            | [Link 9](https://doi.org/10.1145/3626772.3657782)  |       9 |                                    |
|     0 (X) |        |                        | A Large-scale Offer Alignment Model for Partitioning Filtering and Matching Product Offers               | [Link 4](https://doi.org/10.1145/3626772.3661351)  |   (X) 4 |                                    |
|     0 (X) |        |                        | A Unified Search and Recommendation Framework Based on Multi-Scenario Learning for Ranking in E-commerce | [Link 4](https://doi.org/10.1145/3626772.3661356)  |   (X) 4 |                                    |
|     0 (X) |        |                        | Amazon-KG: A Knowledge Graph Enhanced Cross-Domain Recommendation Dataset                                | [Link 7](https://doi.org/10.1145/3626772.3657880)  |   (X) 7 |                                    |

## Grupos

- 25 Seminários (16/06; submetam slides até 15/06)

  1. "In-Context Learning" or: How I learned to stop worrying and love "Applied Information Retrieval" [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657842)
     - Giovana Machado / Clara Fonseca / Jorge Silva / Vitor Vital
  2. An E-Commerce Dataset Revealing Variations during Sales [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657870)
     - Helio Santos / Henrique Medeiros / João Dias
  3. The Power of Noise: Redefining Retrieval for RAG Systems [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657834)
     - José Massucato / Luiz Rocha / Vinicius Faria
  4. Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models [(SIGIR 2024)](https://dl.acm.org/doi/pdf/10.1145/3626772.3657733)
     - Arthur Linhares / Francisco Teixeira / Lorenzo Carneiro / Philipe Dutra
  5. Context Embeddings for Efficient Answer Generation in Retrieval-Augmented Generation [(WSDM 2025)](https://dl.acm.org/doi/10.1145/3701551.3703527)
     - Luis Sousa / Ana Luiza / Christian Vieira / Maria Ferreira

- 26 Seminários (18/06; submetam slides até 17/06)

  1. TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657788)
     - Milena Moreira / Lucas Sacramento
  2. TnT-LLM: Text Mining at Scale with Large Language Models [(KDD 2024)](https://dl.acm.org/doi/pdf/10.1145/3637528.3671647)
     - Gabriel Barros / Gabriel Carvalho / Isabella Gonçalves / Maria Silva
  3. A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657813)
     - Indra Ribeiro / Etelvina Oliveira / Eduardo Klausing
  4. Retrieval with Learned Similarities [(WWW 2025)](https://dl.acm.org/doi/10.1145/3696410.3714822)
     - Caio Lara / Lucas Almeida / Victor Oliveira
  5. TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy [(WWW 2025)](https://dl.acm.org/doi/10.1145/3696410.3714863)
     - Arthur Codama / Denise Ávila / Luciano Alcantara / Bianca Silva

## Apresentações 16/06/2025

### The Power of Noise: Redefining Retrieval for RAG Systems [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657834)

José Massucato / Luiz Rocha / Vinicius Faria

- Comenta sobre documentos irrelevantes sendo colocados após documentos relevantes potencializando o resultado

### "In-Context Learning" or: How I learned to stop worrying and love "Applied Information Retrieval" [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657842)

Giovana Machado / Clara Fonseca / Jorge Silva / Vitor Vital

- Busca facetada

### An E-Commerce Dataset Revealing Variations during Sales [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657870)

Helio Santos / Henrique Medeiros / João Dias

- [URL](https://docs.google.com/presentation/d/1ORS5Qs6XZHlyaRgTJ3h7ISBFOcLFtE1aKVwc62KHd6o)

### Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models [(SIGIR 2024)](https://dl.acm.org/doi/pdf/10.1145/3626772.3657733)

Arthur Linhares / Francisco Teixeira / Lorenzo Carneiro / Philipe Dutra

- Usar diferentes RAGs tende a gerar melhores resultados.
- E se conectarmos RAGs?
- uRAG: unified RAG
  - Um só banco de conhecimento compartilhado entre os modelos
- Usa o BERT pra classificar relevância

### Context Embeddings for Efficient Answer Generation in Retrieval-Augmented Generation [(WSDM 2025)](https://dl.acm.org/doi/10.1145/3701551.3703527)

Luis Sousa / Ana Luiza / Christian Vieira / Maria Ferreira

- Fizeram compressões baseadas em léxico e embeddings
- Compressão baseada em Embeddings
  - AutoCompressor
  - ICAE
  - GridLM
  - xRAG
- Metodologia
  - Documentos são conjuntos de tokens
  - Cálculo dos embeddings pode ser feito offline
  - Eles querem juntar a codificação e decodificação (ou será que é decodificação e compressão?)
- Treinamento (?)
  - Avaliação do Modelo
- Resultados
  - Alcançaram o objetivo de aumentar a eficiência sem perder a qualidade.
- Conclusão

## 26 Seminários (18/06)

### 4. Retrieval with Learned Similarities [(WWW 2025)](https://dl.acm.org/doi/10.1145/3696410.3714822) | Caio Lara / Lucas Almeida / Victor Oliveira

- Mixture of Logits (MoL) como substituto do dot products

---

- Algoritmo Exato
  - Descarta pares de embeddings menores que um determinado suporte
- Algoritmo Aproximado

---

- Análise do erro
- Limite Superior do Erro
- Resultados
  - Atinge > 0.99 do hit rate
  - Melhora em 66x a latência

---

- Dúvidas: Eles procuram melhorar a eficiência ou o resultado?
  - Eficiência
- Dúvida

### 1. TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657788) | Milena Moreira / Lucas Sacramento / Guilherme Soeiro

- Motivação
  - Cenário: LLm para automatização
  - Método comum: Aprendizado por Contexto (ICL)
  - Desafio: Quanto melhor o input, melhor o resultado
- Problemas da Aprendizagem por Contexto
  - Exemplos plausíveis, mas enganosos: ...
  - Limite de contexto: trajetórias têm tokens demais para a janela de contexto da LLM
  - Ruído: Alguns passos intermediários podem gerar ruído e piorar o desempenho
    - Método sinapse: usado no copilot, que usa uma memória contextual
- Framework TRAD
  - Proposta: recupera passos relevantes ao invés do trajeto
    1. Recuperação de Pensamento: passo relevante baseado no raciocínio
    2. Decisão Alinhada: adiciona contexto temporal
  1. Recuperação de Pensamento
     - Etapa 1 (Offline): gera pensamento baseado em base de dados relacionado aos especialistas
     - Etapa 2 (Online): gera pensamento sobre estado atual
     - Busca: gera um ranking do pensamento mais parecido com a proposta especialista
  2. Decisão alinhada: introduz contexto temporal
     - Expansão temporal: recupera os frames do passo anterior e do passo posterior como contextos.
     - Marcação de ordem: usa rótulos como -1, 0 e 1 como sendo "anterior", "atual" e "posterior"
     - Alinhamento de histórico: ...

---

- Pipeline do TRAD
  1. Gera pensamento
  2. Com o pensamento recupera o passo relevante da memória
  3. A expansão temporal adiciona vizinhos ao exemplo
  4. A marcação de ordem relativa define a sequência
  5. O alinhamento histórico...
  6. ...
- Imagem enorme sobre um tipo de jogo com as informações muito bem definidas.
- Experimentos e Benchmarks: dois benchmarks
  - Benchmarks
    - AlfWorld
    - Mind2Web
  - Baselines
    - ReAct
    - Synapse
- Cenários de teste e validação
  - Baseline (Synapse): ...
  - ...
- Nova imagenzona
  - O TRAD conseguiu focar na questão importante
- Desempenho em cenário real
  - ReAct-RD: ...
  - ReAct-RV: ...
- Desempenho em cenário real
  - Tabelona: o TRAD domina todos
- Desempenho em cenário real
  - Pouco aumento de tempo
  - TR ganha da baseline mas perde pro TRAD
  - TRAD ganha em todos os cenários
- Resultados
  - Desempenho: TRAD supera ReAct e Synapse tanto no AlfWorld quanto no Mind2Web
  - Componentes Robustos: todas as partes em conjunto causam benefícios ao modelo
  - Ganhos consistentes: ...
- Conclusão
  - Problema: Trajetória especialista é ineficiente, ruidoso e gera passos enganosos
  - Solução: TRAD
  - Impacto: desempenho e eficiência excepcionais na tomada de decisão

---

- Dúvidas: conseguiram demonstrar que funciona bem no mundo real... espera-se que a base de conhecimento tenha base para a tarefa alvo, então provavelmente é tipo um RAG. Como essa base de pensamentos é construída? Eles mencionam sobre? E se tenho um cenário novo, como eles controem uma base de pensamentos para isso?
  - Resposta: Eles enriqueceram a base com os pensamentos da LLM.

### 2. TnT-LLM: Text Mining at Scale with Large Language Models [(KDD 2024)](https://dl.acm.org/doi/pdf/10.1145/3637528.3671647) | Gabriel Barros / Gabriel Carvalho / Isabella Gonçalves / Maria Silva

Funcionários da Microsoft

- Intro
  - Corpus de texto e converter em dashboards
  - Converter dados não estruturados em dados estruturados com labels bem organizadas.
  - Exemplo rotulação de casos de uso do Copilot.
- Desafios
  - Taxonomia
  - Os classificadores precisaria mde dados anotados.
- 3
  - Label: Schema/Taxonomy
  - Labor-intensive human-in-the-loop framework
  - Text Corpus -> Person -> Label Taxonomy -> Person -> Annotated Data -> Text Classifier -> Labeled Corpus
  - Uma taxonomia criada por uhmano é bastante interpretável, mas pouco escalável, pois o humano teria que fazer tudo.
- 4
  - Text clustering, modelagem de topicos -> dados agrupados -> Label Taxonomy
  - Maior escalabilidade mas com menos interpretabilidade
- 5
  - Visaram substituir o humano na etapa 3 em LLMs para fazer as anotações
- 6
  - A primeira fase é a geração de Taxonomia
  - Separa a base de dados em Batches, a LLM cria taxonomia em um batch para ser usado em outro, e se precisar, modifica os labels. Por fim faz uma review para garantir formatação.
- 7
  - Update vs review
- 8
  - Fase 1: Resumindo e pegando as informações relevantes
  - Fase 2: Gradiente descendente
- 9
  - ...
- 10
  - Prompt do Paper
- 11
  - A avaliação é difícil de se fazer porque não há um ground-truth no qual se basear. Então usaram uma avaliação humana e também com LLMs
- 12
  - Imagenzona de Labels Humanas vs LLM Confusion Matrix
- 13
  - Geração da Taxonomia
    - Fleiss: diversos humanos
    - Cohen: LLM (?)
  - Conclusão: LLM concorda mais com os humanos do que os humanos entre si.
- 14
- 15
  - Classificação Multiclasse tem resultados muito similares que à do GPT-4, mas com custo menor.
- 16
  - É importante usar essa abordagem por dar boas categorias aos dados.

---

- Comentários Rodrygo:
  - É caro usar LLM pra gerar taxonomias. Gerar testes para categorizadores mais baratos.
  - Em RI seria interessante usar isso para armazenar os dados de forma mais enriquecida
  - Dúvidas: Tem LLM pra todo lado. Há discussão sobre usarem a mesma LLM para tudo isso? Ou então foram uma para cada fase?
    - Resposta: Em todos os casos eles usaram apenas o GPT 3.5 ou GPT 4.
  - Um ranqueador que sabe previamente sobre as categorias pode se beneficiar dessa informação

### 3. A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models [(SIGIR 2024)](https://dl.acm.org/doi/10.1145/3626772.3657813) | Indra Ribeiro / Etelvina Oliveira / Eduardo Klausing

- Motivação
  - Zero-Shot document ranking
  - Falta de avaliação comparativa dessas abordagens na literatura
  - Setwise prompting approach
- Diagrama
  - a. Pointwise
    - A LLM diz se é relevante ou não.
    - Verossimilhança: geração de consultas e checagem de quão parecido é
  - b. Listwise
  - c. Pairwise
  - d. Proposed Setwise
    - Derivada alguma coisa
- Limitações das abordagens atuais
  - A eficiência depende de dois aspectos críticos:
    - Número de inferências
    - Número de tokens gerados por inferência

---

- Abordagem Setwise
  - Conjuntos de c documentos
- Adaptando o listwise
- Adaptando o pairwise
  - Logits...
- Adaptando o Pairwise
  - Constante c: quantos documentos são comparados por vez
- Experimentos

---

- Experimentos e Hiperparâmetro 'c'
  - Qualidade do Ranking (Efetividade)
    - NDCG@10
  - Eficiência Computacional
    - Nº de Inferências e Tokens
    - Latência
  - Hiperparâmetro c (Trade-off Central do Setwise)
    - Quanto maior o C, menor é a quantidade das chamadas pra LLM, mas os documentos precisarão ser truncados, então acaba reduzindo a qualidade.
- Análise de resultados: Qualidade do Ranking (Efetividade)
  - Conclusão geral: quase todas as abordagens baseadas em LLM...
  - A abordagem pairwise acaba sendo mais cara

---

- Comentários Rodrygo
  - Dúvida: Queremos produzir um ranking e dar pra LLM o input. Ao invés de dar tudo, faz o pairwise generalisado, dando alguns documentos e deixando eles escolherem? Ao invés de 2 por vez, são alguns por vez?
    - Resposta: Sim.
  - Dúvida: e como é operacionalizado? Instrui ela a interpretar conjunto de documentos C, passando pra ela os documentos C? Manda pra ela uma query com a estratégia, ou no código o programador defina a estratégia?
    - Resposta: ela só dá as subrespostas, então não daria pra passar
  - Então é por fora que seriam contabilizados os vencedores.
  - Dúvida: As várias chamadas contemplam conjuntos disjuntos?
    - Resposta: Ela acredita que a sobreposição não só aconteça como é necessária.

### 5. TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy [(WWW 2025)](https://dl.acm.org/doi/10.1145/3696410.3714863) | Arthur Codama / Denise Ávila / Luciano Alcantara / Bianca Silva

- TourRank: LLMs for Document Ranking
- Motivation
  - Promissor pro zero-shot
    1. Point-wise: independente, pouca efetividade
    2. Pair-wise: $N^2$
    3. List-wise: Melhor mais sensível à ordem (RankGPT); Não paralelizável
       - Talvez seria necessário então fazer um shuffle e rodar várias vezes
- Challenges
  - Limited Input Length
  - Sensitivity to input order
  - Trade-off between cost and performance

---

- Key Idea: Tournament inspired Ranking
  - Inspirado em torneio como FIFA
- ...
- Torunament Stages & Scoring
  - A medida em que avança, ganha pontos.
  - Começa com 100, passam 50, os que perdem ficam com zero
  - Como não dá para enviar todos os documentos no promp, são separados em grupos
- Grouping and Selection
  - Os documentos são embaralhados para reduzir viés por ordenamento
  - Cada grupo pode ser paralelizado
- TourRank Algorithm (Pseudocode)
  - ...
- Why this works?
  - Escalável
  - Paralelizável
  - Aleatoriedade
- Experiments
  - Como TourRank performa?
  - Quão robusto é?
  - ...
  - ...
- Configuração experimental
  - Datasets: TREC DL 19 & 20; BEIR benchmark
  - Metrics: Pointwise: ...; Pairwise: PRP; Listwise: Setwise ...
- Experimental Results
  - TREC DL
    - TourRank-10 outperforms all zero-shot
    - TourRank-2: outperform RankGPT and Setwise
    - Pointwise methods
  - BEIR Benchmark
    - TourRank-10 Melhor em 6 das 8 tarefas
    - TourRank-2: poucos torneios dão bons resultados
- Robustness & Sensitivity
  - Como o TourRank lida com o positional BIAS?
  - O RankGPT acaba ficando pior quando os rankings não estão ordenados.
  - E quantos mais torneios forem realizados, mais preciso é.
  - O modelo não é monolítico. Ele é um modelo de reclassificação.s
- Robustness & ...
  - BM25
  - Contriever
  - SPLADE++ ED
- Robustness & Cost
  - TourRank ...
- TourRank with Other LLMs
  - Works with open-source and closed LLMs
  - ...
- Conclusion
  - Robusto: insensível à ordem
  - Eficiente: ...

---

- Comentários Rodrygo
  - Dúvida: Os grupos são processados na forma listwise?
  - Os experimentos deram uma aula pra convencer que o método é bom.
  - Dúvida: E o paralelismo?
    - Resposta: Tem intratorneio e intertorneio
  - Dúvida: à princípio está no estado da arte. Não sendo um LLM generativo. Mas e em relação a custo? Eles compararam com o MonoBERT?
  - Dúvida: e o custo de tempo?
    - Resposta: ainda é custoso
