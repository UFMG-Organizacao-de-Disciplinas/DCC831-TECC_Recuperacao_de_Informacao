% !TEX root = ../JVFD_Doc.tex

% - 5 points for your documentation, assessed based on a short (pdf) report [$^7$][Note_7] describing your implemented data structures and algorithms, their computational complexity, as well as a discussion of their empirical efficiency (e.g. the time elapsed during each step of indexing and query processing, the speedup achieved via parallelization). Your documentation should also include a characterization of your produced inverted index, including (but not limited to) the following statistics: number of documents, number of tokens, number of inverted lists, and a distribution of the number of postings per inverted list. Likewise, you should include a characterization of the results produced for the provided test queries, such as the number of matched documents per query as well as statistics of the score distributions for the two implemented ranking functions (TFIDF and BM25).
% [Note_7]: https://portalparts.acm.org/hippo/latex_templates/acmart-primary.zip "Your documentation should be no longer than 3 pages and use the ACM LATEX template (sample-sigconf.tex)"

\section{Introduction}

The system consists of two main components implemented in Python 3.13: the \hyperref[subsec:indexer]{\texttt{indexer.py}} for indexing a large corpus of entities from Wikipedia into three index structures (inverted index, document index, and term lexicon) and the \hyperref[subsec:processor]{\texttt{processor.py}} for processing user queries against the indexed data and scoring results using either TFIDF or BM25 ranking functions. The indexing process is designed to handle a large corpus of 4,641,784 documents while adhering to a user-defined memory budget, utilizing parallelization for efficiency.

\subsection{Indexer (\hyperref[subsec:indexing]{\texttt{indexer.py}})} \label{subsec:indexer}

Processes a JSONL corpus containing 4,641,784 Wikipedia entities. For each document, it creates a thread pool to parallelize the indexing process. Considering the user-defined memory budget, the goal was to keep the least memory usage possible while still being able to index the entire corpus. For that matter, it was decided to always load the previouly created index structures from disk, append the new document to them, and then save them back to disk. The goal was to avoid exploding the memory limit.

The indexer ends up creating three index structures: the inverted index, the document index, and the term lexicon. It's importante to notice that the index structures were created considering only the text content of the documents since it most likely contains the terms present in the title and keywords. Another possible approach would be to merge them all together.

\subsection{Query Processor (\hyperref[subsec:query-processing]{\texttt{processor.py}})} \label{subsec:processor}

The query processor is designed to handle user queries against the indexed data. It implements a Document-at-a-Time (DAAT) retrieval model, which processes queries by retrieving postings lists for each term in the query and finding common documents that match all terms. The processor supports two ranking functions: \hyperref[eq:tfidf]{TFIDF} and \hyperref[eq:bm25]{BM25}, allowing users to choose their preferred method for scoring results. It returns the top-10 results in JSON format, including the processed query, matched document IDs, and their corresponding scores.

No parallelization was implemented in the query processor since it was an optional feature and the query processing time was already low enough to not require it, since it was tested with a small subset of 10,000 documents. The DAAT model was built in such a way that it would only load the postings lists for the terms in the query, which reduces the memory usage and speeds up the query processing time. Also, all the documents that didn't present the terms in the query were filtered out before the scoring step, unless no documents matched the query, in which case all documents were scored. This approach was to ensure the recall of the top-10 results, even if they were not so relevant to the query.

\section{Data Structures} \label{sec:data-structures}

The system uses three main index structures to store the indexed data:

\begin{itemize}
  \item \hyperref[subsec:ii]{\textbf{\texttt{inverted\_index.json}}}: maps each term to a list of postings, where each posting is a list containing the document ID and the term frequency in that document.
  \item \hyperref[subsec:di]{\textbf{\texttt{document\_index.json}}}: contains metadata for each document, including their tokenized title, text, keywords and number of unique terms.
  \item \hyperref[subsec:tl]{\textbf{\texttt{term\_lexicon.json}}}: maps each term to a unique ID and includes a histogram of term frequencies across the corpus.
\end{itemize}

\subsection{Inverted Index} \label{subsec:ii}

Notice that the json conversion converted tuples to lists. This approach seemed later unuseful, since a key-value mapping would be a more direct way of getting the term frequency for a document while scoring in the \hyperref{subsec:processor}{query processor}. So, the postings list were later converted for faster scoring purposes, but they are being converted for each query, which is not the most efficient way of doing it and could be improved in the future.

\textbf{Inverted index structure:}

\begin{verbatim}
{
  term_1 (str): [[docID (int), freq (int)], ...],
}
\end{verbatim}

\subsection{Document Index} \label{subsec:di}

Although only the text content of the documents was previously indexed, the document index contains all the tokenized information of the documents, including their title, text, and keywords. Each of them is tokenized, stemmed, and had their stopwords removed. Their length were also computed and stored for later use at the scoring step in the \hyperref{subsec:processor}{query processor}, which isn't actually useful since python stores the length of the list as an attribute what certainly is generated when the json content is loaded. Another possible optimization would be to convert all theses therms into their respective term IDs, which could reduce the memory usage.

\textbf{Document index structure:}

\begin{verbatim}
{
  docID (str): {
    "title": {"length": int, "words":[word_1, ...]},
    "text": {"length": int, "words":[word_1, ...]},
    "keywords": {"length": int,
      "words":[[keyword_1, ...], ...]},
    "unique_terms": {"length": int}
  }, ...
}
\end{verbatim}

\subsection{Term Lexicon} \label{subsec:tl}

The term lexicon is a mapping of each term to a unique ID, which is used to efficiently retrieve postings lists during query processing. It also includes a histogram of term frequencies across the corpus, allowing for quick access to the number of occurrences of each term. For some reason the term ID was stored as a string what was not intended at first but was later kept for consistency.

\textbf{Term Lexicon structure:}

\begin{verbatim}
{
"term2id": {term_1 (str): id_1 (str), ... },
"terms_histogram": {id_1 (str): count_1 (int), ... }
}
\end{verbatim}

\section{Algorithms and Complexity} \label{sec:algorithms}

Two main algorithms are implemented in the system: the indexing process and the query processing. Parallelization apart, the overall algorithms are as follows. They both share some common preprocessing steps, such as tokenization, stemming, and stopword removal using the \href{https://www.nltk.org/}{\texttt{nltk}} library that was modularized in the \texttt{auxiliar.py} file. The \href{https://psutil.readthedocs.io/}{\texttt{psutil}} library was used to monitor the memory usage of the process and ensure it stays within the user-defined budget. As for the processor, its core algorithm is based on the Document-At-A-Time (DAAT) and the BM25 and TFIDF ranking functions, those are located at the \texttt{p\_rankers.py} file.

\subsection{Indexing Process} \label{subsec:indexing}

The indexing process reads the corpus file line by line, tokenizes each document's title, text, and keywords, removes stopwords, stems the terms, and computes a term histogram for each document. It then updates the term lexicon, inverted index, and document index structures in a thread-safe manner while trying to keep the memory usage within the user-defined budget.

\begin{algorithm}[H]
  \caption{Indexer}
  \begin{algorithmic}
    \STATE Initialize index structures
    \FOR{each document in corpus}
    \STATE Loads new line from corpus file as JSON
    \STATE Tokenize, remove stopwords and stem: document title, text, and keywords
    \STATE Compute term histogram for all unique terms in the document
    \STATE \textbf{Compute Term Lexicon:}
    \STATE \quad Create term ID mapping
    \STATE \quad Create term frequency histogram
    \STATE \quad Thread-safe append to term lexicon
    \STATE \textbf{Compute Inverted Index:}
    \quad \FOR{each term in the histogram}
    \STATE \qquad Get term ID from Term Lexicon
    \STATE \qquad If term not in index, create new entry
    \STATE \qquad Append posting [docID, term frequency]
    \STATE \qquad Thread-safe append to inverted index
    \ENDFOR
    \STATE \textbf{Compute Document Index:}
    \STATE \quad Create document entry with ID, title, text, keywords, and unique terms
    \ENDFOR
  \end{algorithmic}
\end{algorithm}

\textbf{Indexing complexity:}

\begin{itemize}
  \item \textbf{Preprocessing:} $O(t)$ per document ($t$ = terms count)
  \item \textbf{Index update:} $O(1)$ per term with concurrent dictionaries
  \item \textbf{Overall:} $O(d \bar{t})$ ($d$ = |documents|, $\bar{t}$ = avg terms per doc)
\end{itemize}

\subsection{Query Processing} \label{subsec:query-processing}

The query processor retrieves postings lists for each term in the query, performs a conjunctive match to find documents that match all terms, if no documents match, it keeps all postings, and then scores the matching documents using the selected ranking function (TFIDF or BM25). The top-10 results are returned in JSON format.

\begin{algorithm}[H]
  \caption{Query Processor}
  \begin{algorithmic}
    \STATE Load index structures to memory
    \FOR{query in \texttt{queries.txt}}
    \STATE Preprocess query (tokenize, stem, remove stopwords)
    \STATE Retrieve postings lists for all query terms
    \STATE From query postings select only documents that match all terms (conjunctive match)
    \IF{no documents match}
    \STATE Keep all postings
    \ENDIF
    \FOR{each DocID in postings}
    \STATE Calculate score using selected ranker (TFIDF/BM25)
    \ENDFOR
    \STATE Append top-10 scored documents for query
    \ENDFOR
    \STATE Return queries results
  \end{algorithmic}
\end{algorithm}

\textbf{Query processing complexity:}

\begin{itemize}
  \item \textbf{Preprocessing:} $O(q)$ per query ($q$ = query terms count)
  \item \textbf{Postings retrieval:} $O(q n)$ per term ($n$ = postings list size)
  \item \textbf{DAAT matching:} $O(m)$ where $m$ = min($|p_1|, |p_2|, ...$) (conjunctive match) and $p_i$ = postings list for term $i$
  \item \textbf{Scoring:} $O(m)$ per document
  \item \textbf{Overall:} $O(q + qn + 2m)$
\end{itemize}

\textbf{Ranking Functions:}

\begin{itemize}
  \item $TFIDF(q, d) = \sum_{t \in q} tf_{t,d} \cdot idf_t$ \label{eq:tfidf}
        \begin{itemize}
          \item $tf_{t,d}: \frac{d_t}{|d|}$
          \item $idf_t = \log{\frac{|Corpus|}{d}}$
        \end{itemize}
  \item $BM25(q, d, b=0.75, k1=1.2) = \sum_{t \in q} tf_{t,d} \cdot idf_t$ \label{eq:bm25}
        \begin{itemize}
          \item $tf_{t,d} = \frac{d_t \cdot (k1+1)}{d_t + k1 \cdot (1-b+b \cdot \frac{|d|}{avgdl})}$
          \item $idf_t = \log{\frac{|Corpus| - Corpus_{tf} + 0.5}{Corpus_{tf} + 0.5}}$
        \end{itemize}
\end{itemize}

\section{Empirical Evaluation}

As part of the empirical evaluation, the indexing and query processing were tested on a subset of 10,000 documents from the full corpus. The tests were meant to evaluate the progression of threading and memory usage during the indexing process.

\subsection{Indexing Performance}

Even after processing 10k documents distributed into queries, it seems that some kind of overwritting ocurred, since the maximum doc id is 10k but only 1843 entries were found at the document index.

\begin{itemize}
  \item All documents: 4,641,784
  \item Number of documents processed: 10,000
  \item Actually stored indexed documents: 1,843
  \item Inverted index terms: 15448
  \item Lexicon maximum term id: 31101
  \item Most Frequent Terms: ``,'': 16969; ``.'': 15319, ``('': 7556, ``)'': 7548
\end{itemize}

\subsection{Query Processing}

Results for sample queries against the 10k document subset:

\begin{table}[htbp]
  \caption{Query Results}
  \label{tab:query-results}
  \begin{tabular}{lrrr}
    \toprule
    \textbf{Query}           & \shortstack{\textbf{Conj.}       \\\textbf{Matches}} & \textbf{Matches} \\
    \midrule
    physics nobel winners    & 0                          & 154 \\
    christopher nolan movies & 0                          & 23  \\
    19th female authors      & 0                          & 67  \\
    german cs universities   & 0                          & 86  \\
    radiohead albums         & 0                          & 324 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Parallelization Analysis} \label{subsec:parallelization}

Thread scaling tests at a corpus size of 1000 documents were conducted to evaluate the impact of parallelization on indexing performance. The \hyperref[tab:threads]{tests} measured total memory usage, time taken, number of lists created, and average list size across different thread counts. The results showed no notable improvements in performance even after parallel processing with 32 threads. The probable cause is the I/O contention due to the disk writes, which limited the benefits of parallelization. Since each thread indexed a document and then wrote it to disk, it was locked to all other threads, which caused a bottleneck. Note that the first entry is the one related to the indexing of the subset of 10k documents, while the others are from the 1000 documents corpus.

\begin{table}[htbp] \label{tab:threads} \centering
  \caption{Thread Indexing scaling tests}
  \begin{tabular}{rrrrrr}
    \toprule
    \textbf{Threads} & \textbf{Total Memory} & \textbf{Time} & \textbf{Lists} & \textbf{Avg Size} \\
    \midrule
    32               & 335.31 MB             & 3936 s        & 15448          & 4.8               \\ %10k Corpus
    32               & 190.87 MB             & 48 s          & 3311           & 2.7               \\
    16               & 184.58 MB             & 49 s          & 4571           & 2.8               \\
    16               & X                     & 54 s          & 4982           & 2.9               \\
    8                & X                     & 65 s          & 6200           & 3.2               \\
    1                & 184.80 MB             & 42 s          & 3801           & 2.8               \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Conclusion}

The implemented system could potentially index large corpora but isn't ideally parallelized due to the I/O contention caused by disk writes. The memory usage was monitored and as an attempt to keep it lower as possible, the index structures were always loaded from disk, updated with the new document, and then saved back to disk. Which indeed kept the memory usage low, but also caused a bottleneck in the indexing process, which proved highly inefficient.

Due to the small number of documents indexed, the conjunctive matching in the query processor was compromised, since no documents matched all the stemmed terms in the queries. However, the processor was able to retrieve documents that matched at least one term in the query in order to be able to score them and return the top-10 results.

% Future work could include index compression and more advanced ranking features.

% ACM's consolidated article template, introduced in 2017, provides a consistent \LaTeX\ style for use across ACM publications, and incorporates accessibility and metadata-extraction functionality necessary for future Digital Library endeavors. Numerous ACM and SIG-specific \LaTeX\ templates have been examined, and their unique features incorporated into this single new template.

% If you are new to publishing with ACM, this document is a valuable guide to the process of preparing your work for publication. If you have published with ACM before, this document provides insight and instruction into more recent changes to the article template.

% The ``\verb|acmart|'' document class can be used to prepare articles for any ACM publication --- conference or journal, and for any stage of publication, from review to final ``camera-ready'' copy, to the author's own version, with {\itshape very} few changes to the source.

% \section{Template Overview}

% As noted in the introduction, the ``\verb|acmart|'' document class can be used to prepare many different kinds of documentation --- a double-anonymous initial submission of a full-length technical paper, a two-page SIGGRAPH Emerging Technologies abstract, a ``camera-ready'' journal article, a SIGCHI Extended Abstract, and more --- all by selecting the appropriate {\itshape template style} and {\itshape template parameters}.

% This document will explain the major features of the document class. For further information, the {\itshape \LaTeX\ User's Guide} is available from \url{https://www.acm.org/publications/proceedings-template}.

% \subsection{Template Styles}

% The primary parameter given to the ``\verb|acmart|'' document class is the {\itshape template style} which corresponds to the kind of publication or SIG publishing the work. This parameter is enclosed in square brackets and is a part of the {\verb|documentclass|} command:

% \begin{verbatim}
%   \documentclass[STYLE]{acmart}
% \end{verbatim}

% Journals use one of three template styles. All but three ACM journals use the {\verb|acmsmall|} template style:

% \begin{itemize}
%   \item {\texttt{acmsmall}}: The default journal template style.
%   \item {\texttt{acmlarge}}: Used by JOCCH and TAP.
%   \item {\texttt{acmtog}}: Used by TOG.
% \end{itemize}

% The majority of conference proceedings documentation will use the {\verb|acmconf|} template style.

% \begin{itemize}
%   \item {\texttt{sigconf}}: The default proceedings template style.
%   \item{\texttt{sigchi}}: Used for SIGCHI conference articles.
%   \item{\texttt{sigplan}}: Used for SIGPLAN conference articles.
% \end{itemize}

% \subsection{Template Parameters}

% In addition to specifying the {\itshape template style} to be used in formatting your work, there are a number of {\itshape template parameters} which modify some part of the applied template style. A complete list of these parameters can be found in the {\itshape \LaTeX\ User's Guide.}

% Frequently-used parameters, or combinations of parameters, include:

% \begin{itemize}
%   \item{\texttt{anonymous,review}}: Suitable for a ``double-anonymous'' conference submission. Anonymizes the work and includes line numbers. Use with the \texttt{\string\acmSubmissionID} command to print the submission's unique ID on each page of the work.
%   \item{\texttt{authorversion}}: Produces a version of the work suitable for posting by the author.
%   \item{\texttt{screen}}: Produces colored hyperlinks.
% \end{itemize}

% This document uses the following string as the first command in the source file:

% \begin{verbatim}
%   \documentclass[sigconf]{acmart}
% \end{verbatim}

% \section{Modifications}

% Modifying the template --- including but not limited to: adjusting margins, typeface sizes, line spacing, paragraph and list definitions, and the use of the ``\verb|\vspace|'' command to manually adjust the vertical spacing between elements of your work --- is not allowed.

%   {\bfseries Your document will be returned to you for revision if modifications are discovered.}

% \section{Typefaces}

% The ``\verb|acmart|'' document class requires the use of the ``Libertine'' typeface family. Your \TeX\ installation should include this set of packages. Please do not substitute other typefaces. The ``\verb|lmodern|'' and ``\verb|ltimes|'' packages should not be used, as they will override the built-in typeface families.

% \section{Title Information}

% The title of your work should use capital letters appropriately - \url{https://capitalizemytitle.com/} has useful rules for capitalization. Use the {\verb|title|} command to define the title of your work. If your work has a subtitle, define it with the {\verb|subtitle|} command.  Do not insert line breaks in your title.

% If your title is lengthy, you must define a short version to be used in the page headers, to prevent overlapping text. The \verb|title| command has a ``short title'' parameter:

% \begin{verbatim}
%   \title[short title]{full title}
% \end{verbatim}

% \section{Authors and Affiliations}

% Each author must be defined separately for accurate metadata identification.  As an exception, multiple authors may share one affiliation. Authors' names should not be abbreviated; use full first names wherever possible. Include authors' e-mail addresses whenever possible.

% Grouping authors' names or e-mail addresses, or providing an ``e-mail alias,'' as shown below, is not acceptable:

% \begin{verbatim}
%   \author{Brooke Aster, David Mehldau}
%   \email{dave,judy,steve@university.edu}
%   \email{firstname.lastname@phillips.org}
% \end{verbatim}

% The \verb|authornote| and \verb|authornotemark| commands allow a note to apply to multiple authors --- for example, if the first two authors of an article contributed equally to the work.

% If your author list is lengthy, you must define a shortened version of the list of authors to be used in the page headers, to prevent overlapping text. The following command should be placed just after the last \verb|\author{}| definition:

% \begin{verbatim}
%   \renewcommand{\shortauthors}{McCartney, et al.}
% \end{verbatim}

% Omitting this command will force the use of a concatenated list of all of the authors' names, which may result in overlapping text in the page headers.

% The article template's documentation, available at \url{https://www.acm.org/publications/proceedings-template}, has a complete explanation of these commands and tips for their effective use.

% Note that authors' addresses are mandatory for journal articles.

% \section{Rights Information}

% Authors of any work published by ACM will need to complete a rights form. Depending on the kind of work, and the rights management choice made by the author, this may be copyright transfer, permission, license, or an OA (open access) agreement.

% Regardless of the rights management choice, the author will receive a copy of the completed rights form once it has been submitted. This form contains \LaTeX\ commands that must be copied into the source document. When the document source is compiled, these commands and their parameters add formatted text to several areas of the final document:

% \begin{itemize}
%   \item the ``ACM Reference Format'' text on the first page.
%   \item the ``rights management'' text on the first page.
%   \item the conference information in the page header(s).
% \end{itemize}

% Rights information is unique to the work; if you are preparing several works for an event, make sure to use the correct set of commands with each of the works.

% The ACM Reference Format text is required for all articles over one page in length, and is optional for one-page articles (abstracts).

% \section{CCS Concepts and User-Defined Keywords}

% Two elements of the ``acmart'' document class provide powerful taxonomic tools for you to help readers find your work in an online search.

% The ACM Computing Classification System --- \url{https://www.acm.org/publications/class-2012} --- is a set of classifiers and concepts that describe the computing discipline. Authors can select entries from this classification system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the commands to be included in the \LaTeX\ source.

% User-defined keywords are a comma-separated list of words and phrases of the authors' choosing, providing a more flexible way of describing the research being presented.

% CCS concepts and user-defined keywords are required for for all articles over two pages in length, and are optional for one- and two-page articles (or abstracts).

% \section{Sectioning Commands}

% Your work should use standard \LaTeX\ sectioning commands: \verb|\section|, \verb|\subsection|, \verb|\subsubsection|, \verb|\paragraph|, and \verb|\subparagraph|. The sectioning levels up to \verb|\subsusection| should be numbered; do not remove the numbering from the commands.

% Simulating a sectioning command by setting the first word or words of a paragraph in boldface or italicized text is {\bfseries not allowed.}

% Below are examples of sectioning commands.

% \subsection{Subsection} \label{sec:subsection}

% This is a subsection.

% \subsubsection{Subsubsection} \label{sec:subsubsection}

% This is a subsubsection.

% \paragraph{Paragraph}

% This is a paragraph.

% \subparagraph{Subparagraph}

% This is a subparagraph.

% \section{Tables}

% The ``\verb|acmart|'' document class includes the ``\verb|booktabs|'' package --- \url{https://ctan.org/pkg/booktabs} --- for preparing high-quality tables.

% Table captions are placed {\itshape above} the table.

% Because tables cannot be split across pages, the best placement for them is typically the top of the page nearest their initial cite.  To ensure this proper ``floating'' placement of tables, use the environment \textbf{table} to enclose the table's contents and the table caption.  The contents of the table itself must go in the \textbf{tabular} environment, to be aligned properly in rows and columns, with the desired horizontal and vertical rules.  Again, detailed instructions on \textbf{tabular} material are found in the \textit{\LaTeX\ User's Guide}.

% Immediately following this sentence is the point at which Table~\ref{tab:freq} is included in the input file; compare the placement of the table here with the table in the printed output of this document.

% \begin{table}
%   \caption{Frequency of Special Characters} \label{tab:freq}
%   \begin{tabular}{ccl}
%     \toprule
%     Non-English or Math & Frequency   & Comments          \\
%     \midrule
%     \O                  & 1 in 1,000  & For Swedish names \\
%     $\pi$               & 1 in 5      & Common in math    \\
%     \$                  & 4 in 5      & Used in business  \\
%     $\Psi^2_1$          & 1 in 40,000 & Unexplained usage \\
%     \bottomrule
%   \end{tabular}
% \end{table}

% To set a wider table, which takes up the whole width of the page's live area, use the environment \textbf{table*} to enclose the table's contents and the table caption.  As with a single-column table, this wide table will ``float'' to a location deemed more desirable. Immediately following this sentence is the point at which Table~\ref{tab:commands} is included in the input file; again, it is instructive to compare the placement of the table here with the table in the printed output of this document.

% \begin{table*}
%   \caption{Some Typical Commands} \label{tab:commands}
%   \begin{tabular}{ccl}
%     \toprule
%     Command                    & A Number & Comments         \\
%     \midrule
%     \texttt{{\char'134}author} & 100      & Author           \\
%     \texttt{{\char'134}table}  & 300      & For tables       \\
%     \texttt{{\char'134}table*} & 400      & For wider tables \\
%     \bottomrule
%   \end{tabular}
% \end{table*}

% Always use midrule to separate table header rows from data rows, and use it only for this purpose. This enables assistive technologies to recognise table headers and support their users in navigating tables more easily.

% \section{Math Equations}

% You may want to display math equations in three distinct styles:
% inline, numbered or non-numbered display.  Each of the three are
% discussed in the next sections.

% \subsection{Inline (In-text) Equations}

% A formula that appears in the running text is called an inline or in-text formula.  It is produced by the \textbf{math} environment, which can be invoked with the usual \texttt{{\char'134}begin\,\ldots{\char'134}end} construction or with the short form \texttt{\$\,\ldots\$}. You can use any of the symbols and structures, from $\alpha$ to $\omega$, available in \LaTeX~\cite{Lamport:LaTeX}; this section will simply show a few examples of in-text equations in context. Notice how this equation:

% \begin{math}
%   \lim_{n\rightarrow \infty}x=0
% \end{math},

% set here in in-line math style, looks slightly different when set in display style. (See next section).

% \subsection{Display Equations}

% A numbered display equation---one set off by vertical space from the text and centered horizontally---is produced by the \textbf{equation} environment. An unnumbered display equation is produced by the \textbf{displaymath} environment.

% Again, in either environment, you can use any of the symbols and structures available in \LaTeX\@; this section will just give a couple of examples of display equations in context.  First, consider the equation, shown as an inline equation above:

% \begin{equation}
%   \lim_{n\rightarrow \infty}x=0
% \end{equation}

% Notice how it is formatted somewhat differently in the \textbf{displaymath} environment.  Now, we'll enter an unnumbered equation:

% \begin{displaymath}
%   \sum_{i=0}^{\infty} x + 1
% \end{displaymath}

% and follow it with another numbered equation:

% \begin{equation}
%   \sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f
% \end{equation}

% just to demonstrate \LaTeX's able handling of numbering.

% \section{Figures}

% The ``\verb|figure|'' environment should be used for figures. One or more images can be placed within a figure. If your figure contains third-party material, you must clearly identify it as such, as shown in the example below.

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{sample-franklin}
%   \caption{1907 Franklin Model D roadster. Photograph by Harris \& Ewing, Inc. [Public domain], via Wikimedia Commons. (\url{https://goo.gl/VLCRBB}).}
%   \Description{A woman and a girl in white dresses sit in an open car.}
% \end{figure}

% Your figures should contain a caption which describes the figure to the reader.

% Figure captions are placed {\itshape below} the figure.

% Every figure should also have a figure description unless it is purely decorative. These descriptions convey what’s in the image to someone who cannot see it. They are also used by search engine crawlers for indexing images, and when images cannot be loaded.

% A figure description must be unformatted plain text less than 2000 characters long (including spaces).  {\bfseries Figure descriptions should not repeat the figure caption – their purpose is to capture important information that is not already provided in the caption or the main text of the paper.} For figures that convey important and complex new information, a short text description may not be adequate. More complex alternative descriptions can be placed in an appendix and referenced in a short figure description. For example, provide a data table capturing the information in a bar chart, or a structured list representing a graph.  For additional information regarding how best to write figure descriptions and why doing this is so important, please see \url{https://www.acm.org/publications/taps/describing-figures/}.

% \subsection{The ``Teaser Figure''}

% A ``teaser figure'' is an image, or set of images in one figure, that are placed after all author and affiliation information, and before the body of the article, spanning the page. If you wish to have such a figure in your article, place the command immediately before the \verb|\maketitle| command:

% \begin{verbatim}
%   \begin{teaserfigure}
%     \includegraphics[width=\textwidth]{sampleteaser}
%     \caption{figure caption}
%     \Description{figure description}
%   \end{teaserfigure}
% \end{verbatim}

% \section{Citations and Bibliographies}

% The use of \BibTeX\ for the preparation and formatting of one's references is strongly recommended. Authors' names should be complete --- use full first names (``Donald E. Knuth'') not initials (``D. E. Knuth'') --- and the salient identifying features of a reference should be included: title, year, volume, number, pages, article DOI, etc.

% The bibliography is included in your source document with these two commands, placed just before the \verb|\end{document}| command:

% \begin{verbatim}
%   \bibliographystyle{ACM-Reference-Format}
%   \bibliography{bibfile}
% \end{verbatim}

% where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|'' suffix, of the \BibTeX\ file.

% Citations and references are numbered by default. A small number of ACM publications have citations and references formatted in the ``author year'' style; for these exceptions, please include this command in the {\bfseries preamble} (before the command ``\verb|\begin{document}|'') of your \LaTeX\ source:

% \begin{verbatim}
%   \citestyle{acmauthoryear}
% \end{verbatim}

% Some examples. A paginated journal article \cite{Abril07}, an enumerated journal article \cite{Cohen07}, a reference to an entire issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a monograph/whole book in a series (see 2a in spec. document) \cite{Harel79}, a divisible-book such as an anthology or compilation \cite{Editor00} followed by the same example, however we only output the series if the volume number is given \cite{Editor00a} (so Editor00a's series should NOT be present since it has no vol. no.), a chapter in a divisible book \cite{Spector90}, a chapter in a divisible book in a series \cite{Douglass98}, a multi-volume work as book \cite{Knuth97}, a couple of articles in a proceedings (of a conference, symposium, workshop for example) (paginated proceedings article) \cite{Andler79, Hagerup1993}, a proceedings article with all possible elements \cite{Smith10}, an example of an enumerated proceedings article \cite{VanGundy07}, an informally published work \cite{Harel78}, a couple of preprints \cite{Bornmann2019, AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a master's thesis: \cite{anisi03}, an online document / world wide web resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05} and (Case 3) a patent \cite{JoeScientist001}, work accepted for publication \cite{rous08}, 'YYYYb'-test for prolific author \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might contain 'duplicate' DOI and URLs (some SIAM articles) \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton: multi-volume works as books \cite{MR781536} and \cite{MR781537}. A couple of citations with DOIs: \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online citations: \cite{TUGInstmem, Thornburg01, CTANacmart}. Artifacts: \cite{R} and \cite{UMassCitations}.

% \section{Acknowledgments}

% Identification of funding sources and other support, and thanks to individuals and groups that assisted in the research and the preparation of the work should be included in an acknowledgment section, which is placed just before the reference section in your document.

% This section has a special environment:

% \begin{verbatim}
%   \begin{acks}
%   ...
%   \end{acks}
% \end{verbatim}

% so that the information contained therein can be more easily collected during the article metadata extraction phase, and to ensure consistency in the spelling of the section heading.

% Authors should not prepare this section as a numbered or unnumbered {\verb|\section|}; please use the ``{\verb|acks|}'' environment.

% \section{Appendices}

% If your work needs an appendix, add it before the ``\verb|\end{document}|'' command at the conclusion of your source document.

% Start the appendix with the ``\verb|appendix|'' command:

% \begin{verbatim}
%   \appendix
% \end{verbatim}

% and note that in the appendix, sections are lettered, not numbered. This document has two appendices, demonstrating the section and subsection identification method.

% \section{Multi-language papers}

% Papers may be written in languages other than English or include titles, subtitles, keywords and abstracts in different languages (as a rule, a paper in a language other than English should include an English title and an English abstract). Use \verb|language=...| for every language used in the paper. The last language indicated is the main language of the paper. For example, a French paper with additional titles and abstracts in English and German may start with the following command

% \begin{verbatim}
%  \documentclass[sigconf, language=english, language=german, language=french]{acmart}
% \end{verbatim}

% The title, subtitle, keywords and abstract will be typeset in the main language of the paper. The commands \verb|\translatedXXX|, \verb|XXX| begin title, subtitle and keywords, can be used to set these elements in the other languages. The environment \verb|translatedabstract| is used to set the translation of the abstract. These commands and environment have a mandatory first argument: the language of the second argument. See \verb|sample-sigconf-i13n.tex| file for examples of their usage.

% \section{SIGCHI Extended Abstracts}

% The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and not in Word) produces a landscape-orientation formatted article, with a wide left margin. Three environments are available for use with the ``\verb|sigchi-a|'' template style, and produce formatted output in the margin:

% \begin{description}
%   \item[\texttt{sidebar}:]  Place formatted text in the margin.
%   \item[\texttt{marginfigure}:] Place a figure in the margin.
%   \item[\texttt{margintable}:] Place a table in the margin.
% \end{description}

% %% The acknowledgments section is defined using the "acks" environment (and NOT an unnumbered section). This ensures the proper identification of the section in the article metadata, and the consistent spelling of the heading.
% \begin{acks}
%   To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}